{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean-subtracted values: [('B', 104.0069879317889), ('G', 116.66876761696767), ('R', 122.6789143406786)]\n",
      "Defining the net!\n",
      "conv1_1\t(64, 3, 3, 3) (64,)\n",
      "conv1_2\t(64, 64, 3, 3) (64,)\n",
      "conv2_1\t(128, 64, 3, 3) (128,)\n",
      "conv2_2\t(128, 128, 3, 3) (128,)\n",
      "conv3_1\t(256, 128, 3, 3) (256,)\n",
      "conv3_2\t(256, 256, 3, 3) (256,)\n",
      "conv3_3\t(256, 256, 3, 3) (256,)\n",
      "conv4_1\t(512, 256, 3, 3) (512,)\n",
      "conv4_2\t(512, 512, 3, 3) (512,)\n",
      "conv4_3\t(512, 512, 3, 3) (512,)\n",
      "conv5_1\t(512, 512, 3, 3) (512,)\n",
      "conv5_2\t(512, 512, 3, 3) (512,)\n",
      "fc_pca\t(350, 100352) (350,)\n",
      "fc_out\t(1, 350) (1,)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This is code for extracting NN features of face image data \n",
    "and then fit a linear model to predict attractiveness of a face\n",
    "Available dataset: TWIN, CHICAGO and MIT\n",
    "Available NN feature: 'caffeNet','vgg16','vggFace' and 'faceSNN'\n",
    "\n",
    "BY Linjie Li\n",
    "Please run this code on guru2 server\n",
    "'''\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "\n",
    "from sklearn.decomposition import PCA as sklearnPCA\n",
    "#homePath = '/raid/linjieli/'\n",
    "homePath = '/home/lli-ms/'\n",
    "# Make sure that caffe is on the python path:\n",
    "caffe_root = homePath+'caffe/'\n",
    "pretrained_model_root = homePath+'caffe/'\n",
    "\n",
    "# run this line one time only!\n",
    "import sys\n",
    "caffePython = pretrained_model_root + 'python'\n",
    "if caffePython not in sys.path:\n",
    "    sys.path.insert(0, caffePython)\n",
    "\n",
    "\n",
    "import caffe\n",
    "# Load mean\n",
    "mu = np.load(caffe_root + 'python/caffe/imagenet/ilsvrc_2012_mean.npy')\n",
    "mu = mu.mean(1).mean(1)  # average over pixels to obtain the mean (BGR) pixel values\n",
    "print 'mean-subtracted values:', zip('BGR', mu)\n",
    "\n",
    "# Load the trained net\n",
    "MODEL = 'vgg16_attr' #'caffeNet','vgg16','vggFace' or 'faceSNN'\n",
    "\n",
    "# saveFigPath = '../Result/'+Dataset+'/'+MODEL\n",
    "# if not os.path.exists(saveFigPath):\n",
    "#     os.makedirs(saveFigPath)\n",
    "    \n",
    "if MODEL == 'vgg16_attr':\n",
    "    MODEL_FILE ='../neuralNet/VGG16/vgg_attractive/vgg16_attr_deploy.prototxt'\n",
    "    PRETRAINED_FILE = caffe_root + '/models/vgg16_social/snapshots/attractive_fc_first_iter_8000.caffemodel'\n",
    "        #'models/vgg16_social/snapshots/attractive_conv5_2_first_iter_10000.caffemodel'\n",
    "    #'models/vgg16_attr/snapshots/first_train_iter_2000.caffemodel'\n",
    "    #'models/vgg16_social/snapshots/attractive_fc_second_iter_8000.caffemodel'\n",
    "    #'models/vgg16_attr/vgg16_attr_max_1000pca_weight_position.caffemodel'\n",
    "#     MODEL_FILE ='../neuralNet/VGG16_guru2/vgg16_attr_deploy.prototxt'\n",
    "#     PRETRAINED_FILE = caffe_root + 'models/vgg16_social/snapshots/attr_fc_train_iter_1000.caffemodel'\n",
    "elif MODEL == 'caffeNet':\n",
    "    MODEL_FILE = caffe_root + 'models/bvlc_reference_caffenet/deploy.prototxt'\n",
    "    PRETRAINED_FILE = caffe_root + 'models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel'\n",
    "elif MODEL == 'vggFace':\n",
    "    MODEL_FILE = caffe_root + 'models/VGGFACE/VGG_CNN_F_deploy.prototxt'\n",
    "    PRETRAINED_FILE = caffe_root + 'models/VGGFACE/VGG_CNN_F.caffemodel'\n",
    "    MEAN_FILE = caffe_root + 'models/VGGFACE/VGG_mean.binaryproto'\n",
    "else:\n",
    "    MODEL = 'faceSNN'\n",
    "    MODEL_FILE = caffe_root +'models/sraonet/siamese_lecun_deploy.prototxt'\n",
    "    PRETRAINED_FILE = caffe_root + 'models/sraonet/snapshots/sraonet_lecun_gd_sub2_iter_100000.caffemodel'\n",
    "    \n",
    "caffe.set_device(1)\n",
    "caffe.set_mode_gpu()\n",
    "if not os.path.isfile(PRETRAINED_FILE):\n",
    "    print(\"No caffemodel!!!\")\n",
    "elif not os.path.isfile(MODEL_FILE):\n",
    "    print(\"No MODEL !!!\")\n",
    "else:\n",
    "    print \"Defining the net!\"\n",
    "    net = caffe.Net(MODEL_FILE,\n",
    "                PRETRAINED_FILE,\n",
    "                caffe.TEST)\n",
    "# input preprocessing: 'data' is the name of the input blob == net.inputs[0]\n",
    "transformer = caffe.io.Transformer({'data': net.blobs['data'].data.shape})\n",
    "if MODEL != 'faceSNN':\n",
    "    # subtract the dataset-mean value in each channel\n",
    "    transformer.set_mean('data', mu)\n",
    "layersParam = dict()\n",
    "#print net.blobs\n",
    "for layer_name, param in net.params.iteritems():\n",
    "    print layer_name + '\\t' + str(param[0].data.shape), str(param[1].data.shape)\n",
    "    layersParam[layer_name]=param\n",
    "transformer.set_transpose('data', (2,0,1))\n",
    "# the reference model operates on images in [0,255] range instead of [0,1]\n",
    "transformer.set_raw_scale('data', 255) \n",
    "# the reference model has channels in BGR order instead of RGB\n",
    "transformer.set_channel_swap('data', (2,1,0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dest = net.blobs['loss']\n",
    "# dest.diff.shape = (1,1)\n",
    "# print dest.diff = np.array([[dest.diff]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if MODEL == 'vgg16_attr':\n",
    "    imgeReshape = [224,224]\n",
    "    featureLayer = 'fc_out' \n",
    "if 'fc' in featureLayer:\n",
    "    featureNum = net.params[featureLayer][1].data.shape[0]\n",
    "elif 'loss' in featureLayer:\n",
    "    featureNum = 1\n",
    "else:\n",
    "    featureNum = net.blobs[featureLayer].data.flatten().shape[0]/net.blobs[featureLayer].data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================Done with Test==========================\n",
      "=====================Done with Train==========================\n"
     ]
    }
   ],
   "source": [
    "# test_file = '../data_list/val_list.txt'\n",
    "# train_file = '../data_list/train_list.txt'\n",
    "# test_file = '../list/attractive_test.txt'\n",
    "# train_file = '../list/attractive_train.txt'\n",
    "test_file = '../data_list/attractive_test.txt'\n",
    "train_file = '../data_list/attractive_train.txt'\n",
    "# test_file = '../data_list/val_list.txt'\n",
    "# train_file = '../data_list/train_list.txt'\n",
    "def readFile(fName):\n",
    "    text_file = open(fName, \"r\")\n",
    "    lines = text_file.read().split('\\n')\n",
    "    text_file.close()\n",
    "    imList = []\n",
    "    ratingList = []\n",
    "    for l in lines:\n",
    "        if len(l) > 2:\n",
    "            l_split = l.split('.jpg ')\n",
    "            #print l_split\n",
    "            imList.append(l_split[0]+'.jpg')\n",
    "            ratingList.append(float(l_split[1]))\n",
    "    return imList,ratingList\n",
    "\n",
    "testIm, testRating = readFile(test_file)\n",
    "trainIm, trainRating = readFile(train_file)\n",
    "from scipy.stats import spearmanr as spearmanr\n",
    "\n",
    "\n",
    "X_test = np.zeros([len(testIm)])\n",
    "totalNum = 0\n",
    "for img in testIm:\n",
    "    imgName = os.path.basename(img)\n",
    "    if imgName.endswith(('.jpg','.png')):\n",
    "        input_image = caffe.io.load_image(img)\n",
    "        net.blobs['data'].reshape(1,3,imgeReshape[0],imgeReshape[1])\n",
    "        net.blobs['data'].data[...] = transformer.preprocess('data', input_image)\n",
    "        #net.blobs['label'].data[...] = np.array(testRating[totalNum])\n",
    "        out = net.forward()\n",
    "        #print np.asarray([net.blobs['loss'].data])\n",
    "        feat = net.blobs[featureLayer].data[0]\n",
    "        #print net.blobs['fc_out'].data[0].shape\n",
    "        X_test[totalNum] = feat.flatten()#[10]\n",
    "        #print features[totalNum]\n",
    "        totalNum +=1\n",
    "    else:\n",
    "        print img\n",
    "print \"=====================Done with Test==========================\"        \n",
    "X_train = np.zeros([len(trainIm)])\n",
    "totalNum = 0\n",
    "for img in trainIm:\n",
    "    imgName = os.path.basename(img)\n",
    "    if imgName.endswith(('.jpg','.png')):\n",
    "        input_image = caffe.io.load_image(img)\n",
    "        net.blobs['data'].reshape(1,3,imgeReshape[0],imgeReshape[1])\n",
    "        net.blobs['data'].data[...] = transformer.preprocess('data', input_image)\n",
    "        #net.blobs['label'].data[...] = np.array(tRating[totalNum])\n",
    "        out = net.forward()\n",
    "        feat = net.blobs[featureLayer].data[0]\n",
    "        X_train[totalNum] = feat.flatten()#[10]\n",
    "        #print features[totalNum]\n",
    "        totalNum +=1\n",
    "    else:\n",
    "        print img\n",
    "print \"=====================Done with Train==========================\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1778,)\n",
      "(1778, 1)\n",
      "(1778, 1)\n",
      "============train=================\n",
      "pearson: 0.672324490358\n",
      "spearman: 0.67224352476\n",
      "============test=================\n",
      "pearson: 0.59256685115\n",
      "spearman: 0.588070586059\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape\n",
    "X_train.shape = (X_train.shape[0],1)\n",
    "print X_train.shape\n",
    "trainRating = np.asarray(trainRating)\n",
    "trainRating.shape = (trainRating.shape[0],1)\n",
    "X_test.shape = (X_test.shape[0],1)\n",
    "print trainRating.shape\n",
    "testRating = np.asarray(testRating)\n",
    "testRating.shape = (testRating.shape[0],1)\n",
    "print \"============train=================\"\n",
    "cor = np.corrcoef(X_train.T, trainRating.T)\n",
    "print 'pearson:',cor[0,1]\n",
    "rcor = spearmanr(trainRating, X_train)\n",
    "print 'spearman:',rcor[0]\n",
    "print \"============test=================\"\n",
    "# Calculate the correlation between prediction and actual rating.\n",
    "cor = np.corrcoef(X_test.T, testRating.T)\n",
    "print 'pearson:',cor[0,1]\n",
    "rcor = spearmanr(testRating, X_test)\n",
    "print 'spearman:',rcor[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============train=================\n",
      "min: [ 3.61050415] max: [ 5.46437979]\n",
      "min: [ 1.933333] max: [ 8.2]\n",
      "============test=================\n",
      "min: [ 3.46682215] max: [ 5.68044424]\n",
      "min: [ 1.733333] max: [ 8.2]\n"
     ]
    }
   ],
   "source": [
    "print \"============train=================\"\n",
    "print 'min:',min(X_test), 'max:',max(X_test)\n",
    "print 'min:',min(testRating), 'max:',max(testRating)\n",
    "print \"============test=================\"\n",
    "print 'min:',min(X_train), 'max:',max(X_train)\n",
    "print 'min:', min(trainRating),'max:',max(trainRating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.19720411] [ 2.866667]\n"
     ]
    }
   ],
   "source": [
    "print X_test[5],testRating[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fc_pcaWeight = layersParam['fc_pca'][0].data\n",
    "print fc_pcaWeight.max()\n",
    "np.nonzero(fc_pcaWeight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train.shape = (X_train[0],1)\n",
    "print X_train.shape\n",
    "trainRating = np.asarray(trainRating)\n",
    "X_test.shape = (X_test.shape[0],1)\n",
    "print trainRating.shape\n",
    "testRating = np.asarray(testRating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "# Do linear regression on feature_arr and mean_rating\n",
    "regr = linear_model.Ridge(fit_intercept=True)\n",
    "regr.fit(X_train, trainRating)\n",
    "train_predict = regr.predict(X_train)\n",
    "\n",
    "# Calculate the correlation between prediction and actual rating.\n",
    "cor = np.corrcoef(train_predict, trainRating)\n",
    "print cor[0,1]\n",
    "rcor = spearmanr(trainRating, train_predict)\n",
    "print rcor[0]\n",
    "\n",
    "test_predict = regr.predict(X_test)\n",
    "# Calculate the correlation between prediction and actual rating.\n",
    "cor = np.corrcoef(test_predict, testRating)\n",
    "print cor[0,1]\n",
    "rcor = spearmanr(testRating, test_predict)\n",
    "print rcor[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allPredict = np.concatenate([train_predict,test_predict]).tolist()\n",
    "allIm = trainIm + testIm\n",
    "sortedIm = [x for (y,x) in sorted(zip(allPredict,allIm))]\n",
    "sortedRating = [y for (y,x) in sorted(zip(allPredict,allIm))]\n",
    "\n",
    "print sortedRating[0]\n",
    "print sortedRating[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pink image \n",
    "# Load image dataset#\n",
    "Dataset = 'white_noise' # 'twin', 'chicago' or 'mit', 'zhihu','pink_noise' or 'funnyFace'\n",
    "if Dataset == 'twin':\n",
    "    imPath = '../../processing/imageProcessing/paddedImages/'\n",
    "    ext = '.png'\n",
    "elif Dataset == 'chicago':\n",
    "    imPath = '../../ChicagoFaceDataset/CFD Version 2.0/CFD 2.0 Images/'\n",
    "    ext = 'N.jpg'\n",
    "elif Dataset == 'mit':\n",
    "    imPath = '../../MIT2kFaceDataset/2kfaces/'\n",
    "    ext = '.jpg'\n",
    "elif Dataset =='funnyFace':\n",
    "    imPath = '../funnyFace/'\n",
    "    ext = '.png'\n",
    "elif Dataset =='pink_noise':\n",
    "    imPath = '../pink_noise_image/'\n",
    "    ext = '.png'\n",
    "else: #Dataset =='white_noise':\n",
    "    imPath = '../white_noise_image/'\n",
    "    ext = '.png'\n",
    "imList = []\n",
    "for dirpath, dirnames, filenames in os.walk(imPath):\n",
    "    for filename in [f for f in filenames if f.endswith(ext)]:\n",
    "        imList.append(os.path.join(dirpath, filename))\n",
    "imList.sort()\n",
    "print len(imList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def writeFile(fName,data):\n",
    "    text_file = open(fName, \"w\")\n",
    "    for d in data:\n",
    "        d = d + '\\n'\n",
    "        text_file.write(d)\n",
    "    text_file.close()\n",
    "fName = '../data_list/pink_image_list.txt'    \n",
    "writeFile(fName, imList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pink_predict = np.zeros([len(imList)])\n",
    "totalNum = 0\n",
    "featureLayer = 'fc_out'\n",
    "for img in imList:\n",
    "    imgName = os.path.basename(img)\n",
    "    if imgName.endswith(('.jpg','.png')):\n",
    "        input_image = caffe.io.load_image(img)\n",
    "        net.blobs['data'].reshape(1,3,imgeReshape[0],imgeReshape[1])\n",
    "        net.blobs['data'].data[...] = transformer.preprocess('data', input_image)\n",
    "        out = net.forward()\n",
    "        feat = net.blobs[featureLayer].data\n",
    "        pink_predict[totalNum] = feat.flatten()\n",
    "        #print features[totalNum]\n",
    "        totalNum +=1\n",
    "    else:\n",
    "        print img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def autolabel(rects,ser):\n",
    "    # attach some text labels\n",
    "    max_label = max(ser)\n",
    "    for rect, var in zip(rects, range(len(ser))):\n",
    "        height = ser[var]\n",
    "        if height > 0:\n",
    "            ypos = 1.02*height\n",
    "        else:\n",
    "            ypos = 1.2*height\n",
    "        if height == max_label:\n",
    "            ax.text((rect.get_x() + rect.get_width()), ypos,\n",
    "                    '(%.5f)' % (height), \n",
    "                    ha='center', va='bottom',fontsize = lSize-13)\n",
    "\n",
    "N = pink_predict[::100].shape[0]\n",
    "lSize = 35\n",
    "ind = np.arange(N)  # the x locations for the groups\n",
    "width = 0.5       # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(30, 10)\n",
    "rects1 = ax.bar(ind, np.absolute(pink_predict[::100]), width, color='r')\n",
    "\n",
    "#add some text for labels, title and axes ticks\n",
    "ax.set_ylabel('Attractiveness',fontsize = lSize)\n",
    "ax.set_title('Predicted Attractiveness Ratings of Random White Noise Images',fontsize = lSize)\n",
    "ax.get_xaxis().set_visible(False)\n",
    "ymin = 0.95*min(pink_predict[::100])\n",
    "ymax = 1.05*max(pink_predict[::100])\n",
    "ax.set_ylim([ymin,ymax])\n",
    "# ax.set_xticks((ind + width/2)[::10])\n",
    "# ax.set_xticklabels(range(1,N+1)[::10],fontsize = lSize-8,rotation=70)\n",
    "ax.tick_params(axis='y', labelsize=lSize-8)\n",
    "\n",
    "#autolabel(rects1,np.absolute(pink_predict[::100]))\n",
    "plt.show()\n",
    "#fig.savefig('../pink_noise_image/predicted_rating.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "sortedIm = [x for (y,x) in sorted(zip(pink_predict,imList))]\n",
    "sortedRating = [y for (y,x) in sorted(zip(pink_predict,imList))]\n",
    "\n",
    "print sortedRating[0]\n",
    "print sortedRating[-1]\n",
    "sortedRating = np.asarray(sortedRating)\n",
    "np.argwhere(sortedRating>1.2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from matplotlib.pyplot import imshow\n",
    "import cv2\n",
    "\n",
    "def PIL2array(img):\n",
    "    return np.array(img.getdata(),\n",
    "                    np.uint8).reshape(img.size[1], img.size[0], 3)\n",
    "def array2PIL(arr, size):\n",
    "    mode = 'RGBA'\n",
    "    arr = arr.reshape(arr.shape[0]*arr.shape[1], arr.shape[2])\n",
    "    if len(arr[0]) == 3:\n",
    "        arr = np.c_[arr, 255*np.ones((len(arr),1), np.uint8)]\n",
    "    return Image.frombuffer(mode, size, arr.tostring(), 'raw', mode, 0, 1)\n",
    "\n",
    "\n",
    "def sum_images(minRating):\n",
    "    sum_arr = np.zeros((224,224,3))\n",
    "    AllIm = np.argwhere(sortedRating>minRating)\n",
    "    N = AllIm.shape[0]\n",
    "    for index in AllIm:\n",
    "        imName = sortedIm[index]\n",
    "        img = Image.open(imName)\n",
    "        im = cv2.imread(imName)\n",
    "        #arr = PIL2array(img)\n",
    "        \n",
    "        sum_arr = sum_arr +im #*sortedRating[index]\n",
    "    sum_arr = (sum_arr- np.min(sum_arr))/(np.max(sum_arr)-np.min(sum_arr))*255\n",
    "    print 'min:',np.min(sum_arr),'max:', np.max(sum_arr)\n",
    "    imshow(sum_arr)\n",
    "#     img = loadImage('foo.jpg')\n",
    "#     arr = PIL2array(img)\n",
    "    #img2 = array2PIL(sum_arr, img.size)\n",
    "    #cv2.imshow('Color image',sum_arr)\n",
    "    #img2.save('sum'+str(minRating)+'.jpg')\n",
    "minRating = sortedRating[0]\n",
    "from scipy import stats\n",
    "z_scoreRating = stats.zscore(sortedRating)\n",
    "sum_images(minRating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'Max:',sortedRating.max()\n",
    "print 'Min:',sortedRating.min()\n",
    "print 'Max:',z_scoreRating.max()\n",
    "print 'Min:',z_scoreRating.min()\n",
    "print z_scoreRating.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
