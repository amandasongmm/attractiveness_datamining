{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13988\n",
      "mean-subtracted values: [('B', 104.0069879317889), ('G', 116.66876761696767), ('R', 122.6789143406786)]\n",
      "Defining the net!\n",
      "conv1_1\t(64, 3, 3, 3) (64,)\n",
      "conv1_2\t(64, 64, 3, 3) (64,)\n",
      "conv2_1\t(128, 64, 3, 3) (128,)\n",
      "conv2_2\t(128, 128, 3, 3) (128,)\n",
      "conv3_1\t(256, 128, 3, 3) (256,)\n",
      "conv3_2\t(256, 256, 3, 3) (256,)\n",
      "conv3_3\t(256, 256, 3, 3) (256,)\n",
      "conv4_1\t(512, 256, 3, 3) (512,)\n",
      "conv4_2\t(512, 512, 3, 3) (512,)\n",
      "conv4_3\t(512, 512, 3, 3) (512,)\n",
      "conv5_1\t(512, 512, 3, 3) (512,)\n",
      "conv5_2\t(512, 512, 3, 3) (512,)\n",
      "conv5_3\t(512, 512, 3, 3) (512,)\n",
      "fc6\t(4096, 25088) (4096,)\n",
      "fc7\t(4096, 4096) (4096,)\n",
      "fc8\t(1000, 4096) (1000,)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This is code for extracting NN features of face image data \n",
    "and then fit a linear model to predict attractiveness of a face\n",
    "Available dataset: TWIN, CHICAGO and MIT\n",
    "Available NN feature: 'caffeNet','vgg16','vggFace' and 'faceSNN'\n",
    "\n",
    "BY Linjie Li\n",
    "Please run this code on guru2 server\n",
    "'''\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "\n",
    "from sklearn.decomposition import PCA as sklearnPCA\n",
    "\n",
    "# Load image dataset#\n",
    "Dataset = 'mit' # 'twin', 'chicago' or 'mit', 'zhihu' or 'funnyFace'\n",
    "if Dataset == 'twin':\n",
    "    imPath = '../../processing/imageProcessing/paddedImages/'\n",
    "    ext = '.png'\n",
    "elif Dataset == 'chicago':\n",
    "    imPath = '../../ChicagoFaceDataset/CFD Version 2.0/CFD 2.0 Images/'\n",
    "    ext = 'N.jpg'\n",
    "elif Dataset == 'mit':\n",
    "    imPath = '../../MIT2kFaceDataset/2kfaces/'\n",
    "    ext = '.jpg'\n",
    "elif Dataset =='funnyFace':\n",
    "    imPath = '../funnyFace/'\n",
    "    ext = '.png'\n",
    "else:\n",
    "    imPath = '../../../zhihu/'\n",
    "    ext = '.jpg'\n",
    "imList = []\n",
    "for dirpath, dirnames, filenames in os.walk(imPath):\n",
    "    for filename in [f for f in filenames if f.endswith(ext)]:\n",
    "        imList.append(os.path.join(dirpath, filename))\n",
    "imList.sort()\n",
    "print len(imList)\n",
    "#print imPath\n",
    "\n",
    "# Make sure that caffe is on the python path:\n",
    "caffe_root = '/home/lli-ms/caffe/'\n",
    "pretrained_model_root = '/home/lli-ms/caffe/'\n",
    "\n",
    "# run this line one time only!\n",
    "import sys\n",
    "caffePython = pretrained_model_root + 'python'\n",
    "if caffePython not in sys.path:\n",
    "    sys.path.insert(0, caffePython)\n",
    "\n",
    "\n",
    "import caffe\n",
    "# Load mean\n",
    "mu = np.load(caffe_root + 'python/caffe/imagenet/ilsvrc_2012_mean.npy')\n",
    "mu = mu.mean(1).mean(1)  # average over pixels to obtain the mean (BGR) pixel values\n",
    "print 'mean-subtracted values:', zip('BGR', mu)\n",
    "\n",
    "# Load the trained net\n",
    "MODEL = 'vgg16' #'caffeNet','vgg16','vggFace' or 'faceSNN'\n",
    "\n",
    "saveFigPath = '../Result/'+Dataset+'/'+MODEL\n",
    "if not os.path.exists(saveFigPath):\n",
    "    os.makedirs(saveFigPath)\n",
    "    \n",
    "if MODEL == 'vgg16':\n",
    "    MODEL_FILE = caffe_root +'models/VGG16/VGG_ILSVRC_16_layers_deploy.prototxt'\n",
    "    PRETRAINED_FILE = caffe_root + 'models/VGG16/VGG_ILSVRC_16_layers.caffemodel'\n",
    "elif MODEL == 'caffeNet':\n",
    "    MODEL_FILE = caffe_root + 'models/bvlc_reference_caffenet/deploy.prototxt'\n",
    "    PRETRAINED_FILE = caffe_root + 'models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel'\n",
    "elif MODEL == 'vggFace':\n",
    "    MODEL_FILE = caffe_root + 'models/VGGFACE/VGG_CNN_F_deploy.prototxt'\n",
    "    PRETRAINED_FILE = caffe_root + 'models/VGGFACE/VGG_CNN_F.caffemodel'\n",
    "    MEAN_FILE = caffe_root + 'models/VGGFACE/VGG_mean.binaryproto'\n",
    "else:\n",
    "    MODEL = 'faceSNN'\n",
    "    MODEL_FILE = caffe_root +'models/sraonet/siamese_lecun_deploy.prototxt'\n",
    "    PRETRAINED_FILE = caffe_root + 'models/sraonet/snapshots/sraonet_lecun_gd_sub2_iter_100000.caffemodel'\n",
    "    \n",
    "caffe.set_device(1)\n",
    "caffe.set_mode_gpu()\n",
    "if not os.path.isfile(PRETRAINED_FILE):\n",
    "    print(\"No caffemodel!!!\")\n",
    "elif not os.path.isfile(MODEL_FILE):\n",
    "    print(\"No MODEL !!!\")\n",
    "else:\n",
    "    print \"Defining the net!\"\n",
    "    net = caffe.Net(MODEL_FILE,\n",
    "                PRETRAINED_FILE,\n",
    "                caffe.TEST)\n",
    "# input preprocessing: 'data' is the name of the input blob == net.inputs[0]\n",
    "transformer = caffe.io.Transformer({'data': net.blobs['data'].data.shape})\n",
    "if MODEL != 'faceSNN':\n",
    "    # subtract the dataset-mean value in each channel\n",
    "    transformer.set_mean('data', mu)\n",
    "for layer_name, param in net.params.iteritems():\n",
    "    print layer_name + '\\t' + str(param[0].data.shape), str(param[1].data.shape)\n",
    "transformer.set_transpose('data', (2,0,1))\n",
    "# the reference model operates on images in [0,255] range instead of [0,1]\n",
    "transformer.set_raw_scale('data', 255) \n",
    "# the reference model has channels in BGR order instead of RGB\n",
    "transformer.set_channel_swap('data', (2,1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13988\n"
     ]
    }
   ],
   "source": [
    "# read in image list \n",
    "def readFile(fName):\n",
    "    text_file = open(fName, \"r\")\n",
    "    lines = text_file.read().split('\\n')\n",
    "    text_file.close()\n",
    "    return lines\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10, 10)\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "if MODEL == 'vgg16' or MODEL == 'vggFace':\n",
    "    imgeReshape = [224,224]\n",
    "    featureLayer = 'conv5_2' \n",
    "elif MODEL == 'caffeNet':\n",
    "    imgeReshape = [227,227]\n",
    "    featureLayer = 'fc6'\n",
    "else:\n",
    "    imgeReshape = [56,46]\n",
    "    featureLayer = 'fc6'\n",
    "if 'fc' in featureLayer:\n",
    "    featureNum = net.params[featureLayer][1].data.shape[0]\n",
    "else:\n",
    "    featureNum = net.blobs[featureLayer].data.flatten().shape[0]/net.blobs[featureLayer].data.shape[0]\n",
    "    \n",
    "if Dataset == 'twin':\n",
    "    features = np.zeros([4,len(imList)/4,featureNum])\n",
    "    perImNum = len(imList)/4\n",
    "    img_type_num = {}\n",
    "    img_type_index = {}\n",
    "    img_type_list = {}\n",
    "    type_index = 0\n",
    "else:\n",
    "    features = np.zeros([len(imList),featureNum])\n",
    "totalNum = 0\n",
    "\n",
    "# print len(imList)\n",
    "for img in imList:\n",
    "    imgName = os.path.basename(img)\n",
    "    if imgName.endswith(('.jpg','.png')):\n",
    "        input_image = caffe.io.load_image(img)\n",
    "        net.blobs['data'].reshape(1,3,imgeReshape[0],imgeReshape[1])\n",
    "        net.blobs['data'].data[...] = transformer.preprocess('data', input_image)\n",
    "        out = net.forward()\n",
    "        feat = net.blobs[featureLayer].data\n",
    "        if Dataset =='twin':\n",
    "            img_type = int(imgName[7:-4])/perImNum\n",
    "            img_index = int(imgName[7:-4])%perImNum\n",
    "            #print 'img_type:',img_type\n",
    "            if img_type in img_type_num.keys():\n",
    "                img_type_num[img_type] = img_type_num[img_type] + 1\n",
    "                img_type_list[img_type][img_index] = img\n",
    "            else:\n",
    "                img_type_num[img_type] = 0\n",
    "                img_type_list[img_type] = [None]*perImNum\n",
    "                img_type_index[img_type] = type_index\n",
    "                type_index +=1\n",
    "            #print 'img_type_index:',img_type_index[img_type]\n",
    "            features[img_type_index[img_type],img_type_num[img_type]] = feat.flatten()\n",
    "        else:\n",
    "            # need to be further revised!\n",
    "            features[totalNum] = feat.flatten()\n",
    "            #print features[totalNum]\n",
    "        totalNum +=1\n",
    "    else:\n",
    "        print img\n",
    "#print len(img_type_num)\n",
    "print totalNum\n",
    "#print img_type_list\n",
    "\n",
    "if Dataset == 'twin':\n",
    "    featureMat = np.zeros((totalNum,featureNum))\n",
    "    k = 0\n",
    "    for i in range(features.shape[0]):\n",
    "        for j in range(features[i].shape[0]):\n",
    "            if sum(features[i,j,:])!=0:\n",
    "                featureMat[k,:] = features[i,j,:]\n",
    "                k +=1\n",
    "else:\n",
    "    featureMat = features\n",
    "#print featureMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of PCs needed to retain 0.900 variance is 766.\n"
     ]
    }
   ],
   "source": [
    "if MODEL != 'faceSNN':\n",
    "    explained_variance = 0.90\n",
    "else:\n",
    "    explained_variance = featureNum\n",
    "\n",
    "sklearn_pca = sklearnPCA(n_components=explained_variance, whiten  = True)\n",
    "feature_transf = sklearn_pca.fit_transform(featureMat)\n",
    "print 'The number of PCs needed to retain %.3f variance is %d.' \\\n",
    "      % (explained_variance, feature_transf.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "featureFunny = featureMat\n",
    "print featureFunny.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13988, 100352)\n",
      "(13988, 100352)\n",
      "The number of PCs needed to retain 255.000 variance is 255.\n"
     ]
    }
   ],
   "source": [
    "print featureMat.shape\n",
    "explained_variance = 255\n",
    "featureCombine = featureMat#np.concatenate((featureMat,featureFunny),axis = 0)\n",
    "print featureCombine.shape\n",
    "sklearn_pca = sklearnPCA(n_components=explained_variance, whiten  = True)\n",
    "feature_comPCA = sklearn_pca.fit_transform(featureCombine)\n",
    "print 'The number of PCs needed to retain %.3f variance is %d.' \\\n",
    "      % (explained_variance, feature_comPCA.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13988,)\n"
     ]
    }
   ],
   "source": [
    "feature_test = feature_comPCA#[-3:,:]\n",
    "predicted_rating = myModel.predict(feature_test)\n",
    "print predicted_rating.shape\n",
    "# imSet = ['../funnyFace/bernie.png','../funnyFace/hilary.png','../funnyFace/trump.png']\n",
    "# import matplotlib.pyplot as plt\n",
    "# fig, (ax1, ax2, ax3) = plt.subplots(nrows=1, ncols=3, figsize=(8, 3),\\\n",
    "#                                     sharex=True, sharey=True)\n",
    "\n",
    "# ax1.imshow(plt.imread(imSet[0]),aspect=1)\n",
    "# ax1.axis('off')\n",
    "# ax1.set_title(str(\"{0:.2f}\".format(predicted_rating[0])), fontsize=20)\n",
    "\n",
    "# ax2.imshow(plt.imread(imSet[1]),aspect=1)\n",
    "# ax2.axis('off')\n",
    "# ax2.set_title(str(\"{0:.2f}\".format(predicted_rating[1])), fontsize=20)\n",
    "\n",
    "# ax3.imshow(plt.imread(imSet[2]),aspect=1)\n",
    "# ax3.axis('off')\n",
    "# ax3.set_title(str(\"{0:.2f}\".format(predicted_rating[2])), fontsize=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13988, 1)\n",
      "(13988, 1)\n",
      "(13988, 2)\n",
      "                                           imageName attractiveness_prediction\n",
      "0   00002adec35b68295041bacd19233d13.jpg_aligned.jpg             3.75229997308\n",
      "1   00003e54e8bb5699d0c0b090774dcedb.jpg_aligned.jpg             4.70687343314\n",
      "2   0002e116192563d13b8b94a734af2fac.jpg_aligned.jpg             5.22332729654\n",
      "3                          000ec3d7a.jpg_aligned.jpg             3.15708950277\n",
      "4                          001031d10.jpg_aligned.jpg             4.71970233582\n",
      "5                          001663d8d.jpg_aligned.jpg             6.39414264308\n",
      "6                          0016bd48a.jpg_aligned.jpg             4.68603242064\n",
      "7   001797961d3887ba9ac1021e554d59c8.jpg_aligned.jpg             4.60012025004\n",
      "8   002179e0199790d5ff12617748653cc0.jpg_aligned.jpg             6.52243503246\n",
      "9   0026664cf55e0661b6be6198e3d51688.jpg_aligned.jpg             3.69739890439\n",
      "10  00273c2fdbcfea379ea1a3302e381195.png_aligned.jpg             6.19550737506\n",
      "11                         0031b87c2.jpg_aligned.jpg             3.06163853919\n",
      "12  00333e833a3aaac7d1ca041b88ea70ef.png_aligned.jpg             4.99507021742\n",
      "13                         00344aae5.jpg_aligned.jpg             4.84157022496\n",
      "14                         003464002.jpg_aligned.jpg              6.0545234745\n",
      "15                         003f49584.jpg_aligned.jpg             4.74944649062\n",
      "16  004034e48f7a20a559549998409aa414.jpg_aligned.jpg             5.96984080808\n",
      "17  004529df389bcc62a6493d6e40b31707.jpg_aligned.jpg              4.1337094345\n",
      "18                         0048d3618.jpg_aligned.jpg             6.20261250067\n",
      "19  004ce5ed4d6e111ea449fdb9f8a06ffb.jpg_aligned.jpg             4.24783803067\n",
      "20  00516aadcc1407f0ea6d1d97f37c1823.jpg_aligned.jpg             4.15408874223\n",
      "21  005a93282c756459a4a1572c29d94c6f.jpg_aligned.jpg             5.42313406926\n",
      "22  005aaea957a12bdf5a5f376408f0686c.jpg_aligned.jpg             4.73165880969\n",
      "23  005de01fde295456c30c910234a22eb7.jpg_aligned.jpg             4.60157828969\n",
      "24                         0068172b7.jpg_aligned.jpg             5.59702214981\n",
      "25                         00681b296.jpg_aligned.jpg             5.17905581176\n",
      "26                         006ca86b2.jpg_aligned.jpg              4.5299122281\n",
      "27  006e22ed98257c1f69091d77e77961e8.jpg_aligned.jpg             5.79350450592\n",
      "28                         006f89ea0.jpg_aligned.jpg             4.57456377976\n",
      "29                         0071448b1.jpg_aligned.jpg             6.73679373494\n",
      "30  00779bb22b1c7c306e9b627c63a9f34c.jpg_aligned.jpg              4.8057424962\n",
      "31  0080297a80d3803d4bd70802ed59f764.jpg_aligned.jpg             4.50447761134\n",
      "32                         00821999f.jpg_aligned.jpg             4.63314393682\n",
      "33                         008469970.jpg_aligned.jpg              5.3333679718\n",
      "34  0089a7aca8b2d272b8bdb13557829b25.jpg_aligned.jpg               5.405560119\n",
      "35                         008ca7283.jpg_aligned.jpg             4.27074072739\n",
      "36  008ea1560d9822e73e784f59ab9c3dbc.jpg_aligned.jpg             4.33764647274\n",
      "37  009a16d162b4cd44ebe4f67d248af864.jpg_aligned.jpg             4.88394243226\n",
      "38  00a26c859d853b023e32947a08febd31.jpg_aligned.jpg             6.84495953671\n",
      "39                         00a933aed.jpg_aligned.jpg             4.14912147104\n",
      "40  00aabec02755583a1438dc6da8a4ffb8.jpg_aligned.jpg             3.06354058282\n",
      "41                         00ace1fbf.jpg_aligned.jpg             4.82139313833\n",
      "42  00bd18e1d9fe34ef1c57b35f9c890024.jpg_aligned.jpg             5.37408179647\n",
      "43                         00c4950c6.jpg_aligned.jpg             5.64578014944\n",
      "44                         00c544f99.jpg_aligned.jpg              5.8067482719\n",
      "45                         00c5d7c27.jpg_aligned.jpg             5.20353678464\n",
      "46  00c9592210df7d2c671e6c059d1655b0.jpg_aligned.jpg             6.01595876217\n",
      "47                         00de1b177.jpg_aligned.jpg             5.30283278439\n",
      "48                         00df9ef89.jpg_aligned.jpg             5.66186617216\n",
      "49  00e260f4611a8b6f8f8c9b00fd481880.jpg_aligned.jpg             5.36318815258\n",
      "50                         00e662397.jpg_aligned.jpg             5.61801740009\n",
      "51  00ee329d8c3c1fa37d8e8e3e3c008ede.jpg_aligned.jpg             4.15321358304\n",
      "52  00f15cade9c5c70edb4b8c3fdadec318.jpg_aligned.jpg             5.49190995008\n",
      "53  00f5f2deab227ec84ea9ad4ba3476f32.jpg_aligned.jpg             4.45821519067\n",
      "54  00fc72d31a9f8daa7f66fae9fd63e7d6.jpg_aligned.jpg             5.41655948795\n",
      "55                         0106983e2.jpg_aligned.jpg             4.80106224284\n",
      "56                         01096f5b7.jpg_aligned.jpg             4.44985626575\n",
      "57                         01110cba6.jpg_aligned.jpg             5.08672728759\n",
      "58  011a4719d533ad45379a5883703694d3.jpg_aligned.jpg             4.20924594218\n",
      "59                         011c3f45e.jpg_aligned.jpg             5.62783756779\n",
      "                                                 ...                       ...\n",
      "\n",
      "[13988 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/dist-packages/pandas/core/common.py:276: DeprecationWarning: numpy boolean negative, the `-` operator, is deprecated, use the `~` operator or the logical_not function instead.\n",
      "  return -res\n",
      "/usr/lib/python2.7/dist-packages/pandas/core/common.py:276: DeprecationWarning: numpy boolean negative, the `-` operator, is deprecated, use the `~` operator or the logical_not function instead.\n",
      "  return -res\n"
     ]
    }
   ],
   "source": [
    "imageNames = [ names.split('/')[5] for names in imList]\n",
    "imageNames = np.asarray(imageNames)\n",
    "imageNames.shape  = (imageNames.shape[0],1)\n",
    "print imageNames.shape\n",
    "attractiveness_predict = np.asarray(predicted_rating)\n",
    "attractiveness_predict.shape  = (attractiveness_predict.shape[0],1)\n",
    "print attractiveness_predict.shape\n",
    "attractiveness_predict = np.concatenate((imageNames,attractiveness_predict),\\\n",
    "                                        axis = 1)\n",
    "print attractiveness_predict.shape\n",
    "df = pd.DataFrame(attractiveness_predict)\n",
    "df.columns = ['imageName','attractiveness_prediction']\n",
    "print df\n",
    "df.to_csv('../../../zhihu/predicted_attractiveness.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "#print sys.path\n",
    "# local\n",
    "# PkgPath = '/Users/Olivialinlin/Documents/Github/attractiveness_datamining/linjieCode/code'\n",
    "# server\n",
    "PkgPath = '/home/lli-ms/attractiveness_datamining/linjieCode/code'\n",
    "\n",
    "if PkgPath not in sys.path:\n",
    "    sys.path.insert(0, PkgPath)\n",
    "#print sys.path\n",
    "from xVal_train_test import Train_Test\n",
    "import pandas as pd\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "featureLayer = 'conv5_2'\n",
    "feature_transf = np.loadtxt(saveFigPath+'/'+featureLayer+'_feature_pca_atrr.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean rating:  4.938305509\n",
      "**************************Result of train and test**************************************\n",
      "number of features: 255\n",
      "On validation set:\n",
      "Residual sum of squares: 0.68\n",
      "Variance score is: 0.53\n",
      "Correlation between predicted ratings and actual ratings is: 0.7327\n",
      " \n",
      "On training set:\n",
      "Residual sum of squares: 0.50\n",
      "Variance score is: 0.65\n",
      "Correlation between predicted ratings and actual ratings is: 0.8090\n",
      "****************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "ratingPath = '../Result/'+Dataset+'/meanRating.csv'\n",
    "mean_rating = pd.read_csv(ratingPath,index_col = 0).as_matrix()[:,0].tolist()\n",
    "mean_rating = map(float, mean_rating)\n",
    "mean_rating = np.array(mean_rating)\n",
    "\n",
    "baseLine = mean_rating.mean()\n",
    "print 'mean rating: ', baseLine\n",
    "\n",
    "predictionModel = sklearn.linear_model.RidgeCV(alphas=np.logspace(-3,2,num=20), fit_intercept=True)\n",
    "myModel \\\n",
    "         = Train_Test(mean_rating, feature_transf,xVal = True,\\\n",
    "                                        pModel = predictionModel,getMaxMin = False,\\\n",
    "                                       numTrain = 50,savePath = '../Result/'+Dataset,\\\n",
    "                                         MODEL= MODEL, plotPredActual = False,returnModel = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imListNP = np.asarray(imList)\n",
    "minImage = imListNP[minIndex]\n",
    "maxImage = imListNP[maxIndex]\n",
    "import matplotlib.pyplot as plt\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(nrows=1, ncols=3, figsize=(8, 3), sharex=True, sharey=True)\n",
    "\n",
    "ax1.imshow(plt.imread(maxImage[-1]))\n",
    "ax1.axis('off')\n",
    "ax1.set_title(str(\"{0:.2f}\".format(maxRating[-1])), fontsize=20)\n",
    "\n",
    "ax2.imshow(plt.imread(maxImage[-2]))\n",
    "ax2.axis('off')\n",
    "ax2.set_title(str(\"{0:.2f}\".format(maxRating[-2])), fontsize=20)\n",
    "\n",
    "ax3.imshow(plt.imread(maxImage[-3]))\n",
    "ax3.axis('off')\n",
    "ax3.set_title(str(\"{0:.2f}\".format(maxRating[-3])), fontsize=20)\n",
    "\n",
    "\n",
    "# ax4.imshow(edges3, cmap=plt.cm.gray)\n",
    "# ax4.axis('off')\n",
    "# ax4.set_title('auto', fontsize=20)\n",
    "\n",
    "\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(nrows=1, ncols=3, figsize=(8, 3), sharex=True, sharey=True)\n",
    "\n",
    "ax1.imshow(plt.imread(minImage[0]))\n",
    "ax1.axis('off')\n",
    "ax1.set_title(str(\"{0:.2f}\".format(minRating[0])), fontsize=20)\n",
    "\n",
    "ax2.imshow(plt.imread(minImage[1]))\n",
    "ax2.axis('off')\n",
    "ax2.set_title(str(\"{0:.2f}\".format(minRating[1])), fontsize=20)\n",
    "\n",
    "ax3.imshow(plt.imread(minImage[2]))\n",
    "ax3.axis('off')\n",
    "ax3.set_title(str(\"{0:.2f}\".format(minRating[2])), fontsize=20)\n",
    "\n",
    "\n",
    "# ax4.imshow(edges3, cmap=plt.cm.gray)\n",
    "# ax4.axis('off')\n",
    "# ax4.set_title('auto', fontsize=20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.savetxt(saveFigPath+'/'+featureLayer+'_feature_pca_atrr.csv', feature_transf, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean rating:  4.938305509\n",
      "MODEL: vgg16\n",
      "Defining the net!\n",
      "conv1_1\t(10, 64, 224, 224) (64,)\n",
      "conv1_2\t(10, 64, 224, 224) (64,)\n",
      "conv2_1\t(10, 128, 112, 112) (128,)\n",
      "conv2_2\t(10, 128, 112, 112) (128,)\n",
      "conv3_1\t(10, 256, 56, 56) (256,)\n",
      "conv3_2\t(10, 256, 56, 56) (256,)\n",
      "conv3_3\t(10, 256, 56, 56) (256,)\n",
      "conv4_1\t(10, 512, 28, 28) (512,)\n",
      "conv4_2\t(10, 512, 28, 28) (512,)\n",
      "conv4_3\t(10, 512, 28, 28) (512,)\n",
      "conv5_1\t(10, 512, 14, 14) (512,)\n",
      "conv5_2\t(10, 512, 14, 14) (512,)\n",
      "conv5_3\t(10, 512, 14, 14) (512,)\n",
      "fc6\t(10, 4096) (4096,)\n",
      "fc7\t(10, 4096) (4096,)\n",
      "fc8\t(10, 1000) (1000,)\n",
      "Layer Set up: vgg16 conv1_1\n",
      "2222\n"
     ]
    }
   ],
   "source": [
    "ratingPath = '../Result/'+Dataset+'/meanRating.csv'\n",
    "mean_rating = pd.read_csv(ratingPath,index_col = 0).as_matrix()[:,0].tolist()\n",
    "mean_rating = map(float, mean_rating)\n",
    "mean_rating = np.array(mean_rating)\n",
    "\n",
    "baseLine = mean_rating.mean()\n",
    "print 'mean rating: ', baseLine\n",
    "\n",
    "MODEL_ARR = ['vgg16']#,'caffeNet','vggFace']\n",
    "caffe.set_device(1)\n",
    "caffe.set_mode_gpu()\n",
    "for MODEL in MODEL_ARR:\n",
    "    print 'MODEL: '+MODEL\n",
    "    saveFigPath = '../Result/'+Dataset+'/'+MODEL\n",
    "    if not os.path.exists(saveFigPath):\n",
    "        os.makedirs(saveFigPath)\n",
    "\n",
    "    if MODEL == 'vgg16':\n",
    "        MODEL_FILE = caffe_root +'models/VGG16/VGG_ILSVRC_16_layers_deploy.prototxt'\n",
    "        PRETRAINED_FILE = caffe_root + 'models/VGG16/VGG_ILSVRC_16_layers.caffemodel'\n",
    "    elif MODEL == 'caffeNet':\n",
    "        MODEL_FILE = caffe_root + 'models/bvlc_reference_caffenet/deploy.prototxt'\n",
    "        PRETRAINED_FILE = caffe_root + 'models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel'\n",
    "    else: \n",
    "        #MODEL == 'vggFace'\n",
    "        MODEL_FILE = caffe_root + 'models/VGGFACE/VGG_CNN_F_deploy.prototxt'\n",
    "        PRETRAINED_FILE = caffe_root + 'models/VGGFACE/VGG_CNN_F.caffemodel'\n",
    "        MEAN_FILE = caffe_root + 'models/VGGFACE/VGG_mean.binaryproto'\n",
    "\n",
    "    if not os.path.isfile(PRETRAINED_FILE):\n",
    "        print(\"No caffemodel!!!\")\n",
    "    elif not os.path.isfile(MODEL_FILE):\n",
    "        print(\"No MODEL !!!\")\n",
    "    else:\n",
    "        print \"Defining the net!\"\n",
    "        net = caffe.Net(MODEL_FILE,\n",
    "                    PRETRAINED_FILE,\n",
    "                    caffe.TEST)\n",
    "    # input preprocessing: 'data' is the name of the input blob == net.inputs[0]\n",
    "    transformer = caffe.io.Transformer({'data': net.blobs['data'].data.shape})\n",
    "    # subtract the dataset-mean value in each channel\n",
    "    transformer.set_mean('data', mu)\n",
    "    transformer.set_transpose('data', (2,0,1))\n",
    "    # the reference model operates on images in [0,255] range instead of [0,1]\n",
    "    transformer.set_raw_scale('data', 255) \n",
    "    # the reference model has channels in BGR order instead of RGB\n",
    "    transformer.set_channel_swap('data', (2,1,0))\n",
    "    plt.rcParams['figure.figsize'] = (10, 10)\n",
    "    plt.rcParams['image.interpolation'] = 'nearest'\n",
    "    plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "    if MODEL == 'vgg16' or MODEL == 'vggFace':\n",
    "        imgeReshape = [224,224]\n",
    "    else:\n",
    "        #MODEL == 'caffeNet'\n",
    "        imgeReshape = [227,227]\n",
    "    for layer_name, param in net.params.iteritems():\n",
    "        print layer_name + '\\t' + str(net.blobs[layer_name].data.shape), str(param[1].data.shape)  \n",
    "    for layer_name, param in net.params.iteritems():\n",
    "        featureLayer = layer_name\n",
    "        print 'Layer Set up: '+MODEL+' '+featureLayer\n",
    "        if 'fc' in featureLayer:\n",
    "            featureNum = net.params[featureLayer][1].data.shape[0]\n",
    "        else:\n",
    "            featureNum = net.blobs[featureLayer].data.flatten().shape[0]/net.blobs[featureLayer].data.shape[0]\n",
    "        features = np.zeros([len(imList),featureNum])\n",
    "        totalNum = 0\n",
    "\n",
    "        # print len(imList)\n",
    "        for img in imList:\n",
    "            imgName = os.path.basename(img)\n",
    "            if imgName.endswith(('.jpg','.png')):\n",
    "                input_image = caffe.io.load_image(img)\n",
    "                net.blobs['data'].reshape(1,3,imgeReshape[0],imgeReshape[1])\n",
    "                net.blobs['data'].data[...] = transformer.preprocess('data', input_image)\n",
    "                out = net.forward()\n",
    "                feat = net.blobs[featureLayer].data\n",
    "#                 print feat.shape\n",
    "                features[totalNum] = feat.flatten()\n",
    "                totalNum +=1\n",
    "            else:\n",
    "                print img\n",
    "        print totalNum\n",
    "        featureMat = features\n",
    "        \n",
    "        explained_variance = 0.99\n",
    "        sklearn_pca = sklearnPCA(n_components=explained_variance, whiten  = True)\n",
    "        feature_transf = sklearn_pca.fit_transform(featureMat)\n",
    "        print 'The number of PCs needed to retain %.3f variance is %d.' \\\n",
    "              % (explained_variance, feature_transf.shape[1])\n",
    "        predictionModel = sklearn.linear_model.RidgeCV(alphas=np.logspace(-3,2,num=20), fit_intercept=True)\n",
    "        Train_Test(mean_rating, feature_transf,xVal = True, pModel = predictionModel,\\\n",
    "                       numTrain = 50,savePath = '../Result/'+Dataset,MODEL= MODEL)\n",
    "        print 'One layer done!'\n",
    "        print '######################################'\n",
    "        print '######################################'\n",
    "    print 'One MODEL done!'\n",
    "    print '!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!'\n",
    "    print '!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import pandas as pd\n",
    "# Load image dataset#\n",
    "Dataset = 'mit' # 'twin', 'chicago' or 'mit'\n",
    "if Dataset == 'twin':\n",
    "    imPath = '../../processing/imageProcessing/paddedImages/'\n",
    "    ext = '.png'\n",
    "elif Dataset == 'chicago':\n",
    "    imPath = '../../ChicagoFaceDataset/CFD Version 2.0/CFD 2.0 Images/'\n",
    "    ext = 'N.jpg'\n",
    "else:\n",
    "    imPath = '../../MIT2kFaceDataset/2kfaces/'\n",
    "    ext = '.jpg'\n",
    "geometric_matrix = pd.read_csv('../../MIT2kFaceDataset/clean_data/geometric_all.csv',index_col = 0)\n",
    "imList = geometric_matrix.imgName.tolist()\n",
    "imList = [imPath+ imgStr for imgStr in imList]\n",
    "print len(imList)\n",
    "print imPath\n",
    "\n",
    "# Make sure that caffe is on the python path:\n",
    "caffe_root = '/home/lli-ms/caffe/'\n",
    "pretrained_model_root = '/home/lli-ms/caffe/'\n",
    "\n",
    "# run this line one time only!\n",
    "import sys\n",
    "caffePython = pretrained_model_root + 'python'\n",
    "if caffePython not in sys.path:\n",
    "    sys.path.insert(0, caffePython)\n",
    "\n",
    "\n",
    "import caffe\n",
    "# Load mean\n",
    "mu = np.load(caffe_root + 'python/caffe/imagenet/ilsvrc_2012_mean.npy')\n",
    "mu = mu.mean(1).mean(1)  # average over pixels to obtain the mean (BGR) pixel values\n",
    "print 'mean-subtracted values:', zip('BGR', mu)\n",
    "\n",
    "# Load the trained net\n",
    "MODEL = 'caffeNet' #'caffeNet','vgg16','vggFace' or 'faceSNN'\n",
    "\n",
    "saveFigPath = '../Result/'+Dataset+'/'+MODEL\n",
    "if not os.path.exists(saveFigPath):\n",
    "    os.makedirs(saveFigPath)\n",
    "    \n",
    "if MODEL == 'vgg16':\n",
    "    MODEL_FILE = caffe_root +'models/VGG16/VGG_ILSVRC_16_layers_deploy.prototxt'\n",
    "    PRETRAINED_FILE = caffe_root + 'models/VGG16/VGG_ILSVRC_16_layers.caffemodel'\n",
    "elif MODEL == 'caffeNet':\n",
    "    MODEL_FILE = caffe_root + 'models/bvlc_reference_caffenet/deploy.prototxt'\n",
    "    PRETRAINED_FILE = caffe_root + 'models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel'\n",
    "elif MODEL == 'vggFace':\n",
    "    MODEL_FILE = caffe_root + 'models/VGGFACE/VGG_CNN_F_deploy.prototxt'\n",
    "    PRETRAINED_FILE = caffe_root + 'models/VGGFACE/VGG_CNN_F.caffemodel'\n",
    "    MEAN_FILE = caffe_root + 'models/VGGFACE/VGG_mean.binaryproto'\n",
    "else:\n",
    "    MODEL = 'faceSNN'\n",
    "    MODEL_FILE = caffe_root +'models/sraonet/siamese_lecun_deploy.prototxt'\n",
    "    PRETRAINED_FILE = caffe_root + 'models/sraonet/snapshots/sraonet_lecun_gd_sub2_iter_100000.caffemodel'\n",
    "    \n",
    "caffe.set_device(1)\n",
    "caffe.set_mode_gpu()\n",
    "if not os.path.isfile(PRETRAINED_FILE):\n",
    "    print(\"No caffemodel!!!\")\n",
    "elif not os.path.isfile(MODEL_FILE):\n",
    "    print(\"No MODEL !!!\")\n",
    "else:\n",
    "    print \"Defining the net!\"\n",
    "    net = caffe.Net(MODEL_FILE,\n",
    "                PRETRAINED_FILE,\n",
    "                caffe.TEST)\n",
    "# input preprocessing: 'data' is the name of the input blob == net.inputs[0]\n",
    "transformer = caffe.io.Transformer({'data': net.blobs['data'].data.shape})\n",
    "if MODEL != 'faceSNN':\n",
    "    # subtract the dataset-mean value in each channel\n",
    "    transformer.set_mean('data', mu)\n",
    "    print 'featureNum: ',net.params['fc7'][1].data.shape\n",
    "else:\n",
    "    print 'featureNum: ',net.params['fc6'][1].data.shape\n",
    "transformer.set_transpose('data', (2,0,1))\n",
    "# the reference model operates on images in [0,255] range instead of [0,1]\n",
    "transformer.set_raw_scale('data', 255) \n",
    "# the reference model has channels in BGR order instead of RGB\n",
    "transformer.set_channel_swap('data', (2,1,0))\n",
    "# read in image list \n",
    "def readFile(fName):\n",
    "    text_file = open(fName, \"r\")\n",
    "    lines = text_file.read().split('\\n')\n",
    "    text_file.close()\n",
    "    return lines\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10, 10)\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "if MODEL == 'vgg16' or MODEL == 'vggFace':\n",
    "    featureNum = 4096\n",
    "    imgeReshape = [224,224]\n",
    "    featureLayer = 'fc7'\n",
    "elif MODEL == 'caffeNet':\n",
    "    featureNum = 4096\n",
    "    imgeReshape = [227,227]\n",
    "    featureLayer = 'fc7'\n",
    "else:\n",
    "    featureNum = 50\n",
    "    imgeReshape = [56,46]\n",
    "    featureLayer = 'fc6'\n",
    "\n",
    "if Dataset == 'twin':\n",
    "    features = np.zeros([4,len(imList)/4,featureNum])\n",
    "    perImNum = len(imList)/4\n",
    "    img_type_num = {}\n",
    "    img_type_index = {}\n",
    "    img_type_list = {}\n",
    "    type_index = 0\n",
    "else:\n",
    "    features = np.zeros([len(imList),featureNum])\n",
    "totalNum = 0\n",
    "\n",
    "# print len(imList)\n",
    "for img in imList:\n",
    "    imgName = os.path.basename(img)\n",
    "    if imgName.endswith(('.jpg','.png')):\n",
    "        input_image = caffe.io.load_image(img)\n",
    "        net.blobs['data'].reshape(1,3,imgeReshape[0],imgeReshape[1])\n",
    "        net.blobs['data'].data[...] = transformer.preprocess('data', input_image)\n",
    "        out = net.forward()\n",
    "        feat = net.blobs[featureLayer].data\n",
    "        if Dataset =='twin':\n",
    "            img_type = int(imgName[7:-4])/perImNum\n",
    "            img_index = int(imgName[7:-4])%perImNum\n",
    "            #print 'img_type:',img_type\n",
    "            if img_type in img_type_num.keys():\n",
    "                img_type_num[img_type] = img_type_num[img_type] + 1\n",
    "                img_type_list[img_type][img_index] = img\n",
    "            else:\n",
    "                img_type_num[img_type] = 0\n",
    "                img_type_list[img_type] = [None]*perImNum\n",
    "                img_type_index[img_type] = type_index\n",
    "                type_index +=1\n",
    "            #print 'img_type_index:',img_type_index[img_type]\n",
    "            features[img_type_index[img_type],img_type_num[img_type]] = feat.flatten()\n",
    "        else:\n",
    "            # need to be further revised!\n",
    "            features[totalNum] = feat.flatten()\n",
    "            #print features[totalNum]\n",
    "        totalNum +=1\n",
    "    else:\n",
    "        print img\n",
    "#print len(img_type_num)\n",
    "print totalNum\n",
    "#print img_type_list\n",
    "\n",
    "if Dataset == 'twin':\n",
    "    featureMat = np.zeros((totalNum,featureNum))\n",
    "    k = 0\n",
    "    for i in range(features.shape[0]):\n",
    "        for j in range(features[i].shape[0]):\n",
    "            if sum(features[i,j,:])!=0:\n",
    "                featureMat[k,:] = features[i,j,:]\n",
    "                k +=1\n",
    "else:\n",
    "    featureMat = features\n",
    "#print featureMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA as sklearnPCA\n",
    "if MODEL != 'faceSNN':\n",
    "    explained_variance = 0.99\n",
    "    #explained_variance = 50\n",
    "else:\n",
    "    explained_variance = featureNum\n",
    "\n",
    "config_feature = geometric_matrix.loc[:,'nose_width':'AV']\n",
    "print config_feature.columns \n",
    "feature_combine = np.concatenate((config_feature,featureMat),axis = 1)\n",
    "sklearn_pca = sklearnPCA(n_components=explained_variance, whiten  = True)\n",
    "feature_combine_transf = sklearn_pca.fit_transform(feature_combine)\n",
    "print 'The number of PCs needed to retain %.3f variance is %d.' \\\n",
    "      % (explained_variance, feature_combine_transf.shape[1])\n",
    "    \n",
    "sklearn_pca = sklearnPCA(n_components=explained_variance, whiten  = True)\n",
    "feature_transf = sklearn_pca.fit_transform(featureMat)\n",
    "print 'The number of PCs needed to retain %.3f variance is %d.' \\\n",
    "      % (explained_variance, feature_transf.shape[1])\n",
    "\n",
    "\n",
    "sklearn_pca = sklearnPCA(n_components=explained_variance, whiten  = True)\n",
    "config_transf = sklearn_pca.fit_transform(config_feature)\n",
    "print 'The number of PCs needed to retain %.3f variance is %d.' \\\n",
    "      % (explained_variance, config_transf.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_rating = geometric_matrix.attractive.as_matrix()\n",
    "print len(mean_rating)\n",
    "mean_rating = map(float, mean_rating)\n",
    "mean_rating = np.array(mean_rating)\n",
    "import sys\n",
    "#print sys.path\n",
    "# local\n",
    "# PkgPath = '/Users/Olivialinlin/Documents/Github/attractiveness_datamining/linjieCode/code'\n",
    "# server\n",
    "PkgPath = '/home/lli-ms/attractiveness_datamining/linjieCode/code'\n",
    "\n",
    "if PkgPath not in sys.path:\n",
    "    sys.path.insert(0, PkgPath)\n",
    "#print sys.path\n",
    "from xVal_train_test import Train_Test\n",
    "import pandas as pd\n",
    "feature_transf = feature_combine_transf #np.concatenate((config_transf,feature_transf),axis = 1)\n",
    "print feature_transf.shape\n",
    "baseLine = mean_rating.mean()\n",
    "print 'mean rating: ', baseLine\n",
    "import sklearn\n",
    "predictionModel = sklearn.linear_model.RidgeCV(alphas=np.logspace(-3,2,num=20), fit_intercept=True)\n",
    "Train_Test(mean_rating, feature_transf,xVal = True, pModel = predictionModel,\\\n",
    "               numTrain = 100,savePath = '../Result/'+Dataset,MODEL= MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import linear_model\n",
    "ratingPath = '../Result/'+Dataset+'/meanRating.csv'\n",
    "mean_rating = pd.read_csv(ratingPath,index_col = 0).as_matrix()[:,0].tolist()\n",
    "mean_rating = map(float, mean_rating)\n",
    "mean_rating = np.array(mean_rating)\n",
    "\n",
    "baseLine = mean_rating.mean()\n",
    "print 'mean rating: ', baseLine\n",
    "# cross validation to determine the number of features\n",
    "from sklearn import cross_validation\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(\\\n",
    "                       feature_transf, mean_rating, test_size=0.2, random_state=0)\n",
    "corrList = []\n",
    "varList = []\n",
    "mseList = []\n",
    "if MODEL != 'faceSNN':\n",
    "    numFeature = [40,50,60,65,70,75,80,90,100,120,150,200,250,300,350]\n",
    "else:\n",
    "    numFeature = [10,20,30,40,50]\n",
    "for numF in numFeature:\n",
    "    X_train_hat = X_train[:,:numF]\n",
    "#     print X_train_hat.shape\n",
    "#     print y_train.shape\n",
    "    X_test_hat = X_test[:,:numF]\n",
    "    # Do linear regression on feature_arr and mean_rating\n",
    "    regr = linear_model.Ridge(fit_intercept=True)\n",
    "    regr.fit(X_train_hat, y_train)\n",
    "    predicted_rating = regr.predict(X_test_hat)\n",
    "    #rectified_rating = np.around(predicted_rating, decimals=0)\n",
    "    # Calculate the mean square error\n",
    "    MSE = np.mean((predicted_rating - y_test) ** 2)\n",
    "    mseList.append(MSE)\n",
    "    \n",
    "    # Returns the coefficient of determination R^2 of the prediction.\n",
    "    '''\n",
    "    The coefficient R^2 is defined as (1 - u/v), \n",
    "    where u is the regression sum of squares ((y_true - y_pred) ** 2).sum() \n",
    "    and v is the residual sum of squares ((y_true - y_true.mean()) ** 2).sum(). \n",
    "    Best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse).\n",
    "    A constant model that always predicts the expected value of y, \n",
    "    disregarding the input features, would get a R^2 score of 0.0.\n",
    "    '''\n",
    "    variance_score = regr.score(X_test_hat, y_test)\n",
    "    varList.append(variance_score)\n",
    "    \n",
    "    # Calculate the correlation between prediction and actual rating.\n",
    "    cor = np.corrcoef(predicted_rating, y_test)\n",
    "    corrList.append(cor[0,1])\n",
    "\n",
    "print 'Correlation: ', max(corrList)\n",
    "print 'num of features: ',numFeature[np.argmax(corrList)]\n",
    "print 'R^2 score: ',max(varList)\n",
    "print 'num of features: ',numFeature[np.argmax(varList)]\n",
    "print 'MSE: ',min(mseList)\n",
    "print 'num of features: ',numFeature[np.argmin(mseList)]\n",
    "optNumFea = numFeature[np.argmax(corrList)]\n",
    "X_train_hat = X_train[:,:optNumFea]\n",
    "X_test_hat = X_test[:,:optNumFea]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Do linear regression on feature_arr and mean_rating\n",
    "regr = linear_model.Ridge(fit_intercept=True)\n",
    "regr.fit(X_train_hat, y_train)\n",
    "predicted_rating = regr.predict(X_train_hat)\n",
    "#rectified_rating = np.around(predicted_rating, decimals=0)\n",
    "\n",
    "# The coefficients\n",
    "#print 'Coefficients: ', regr.coef_[0:10]\n",
    "print 'Intercept: ', regr.intercept_\n",
    "# Calculate the mean square error\n",
    "MSE = np.mean((predicted_rating - y_train) ** 2)\n",
    "print 'Residual sum of squares: %.2f' % MSE\n",
    "\n",
    "# Calculate how much variance is explained\n",
    "variance_score = regr.score(X_train_hat, y_train)\n",
    "print 'Variance score is: %.2f' % variance_score\n",
    "\n",
    "# Calculate the correlation between prediction and actual rating.\n",
    "cor = np.corrcoef(predicted_rating, y_train)\n",
    "print 'Correlation is: %.2f' %cor[0, 1]\n",
    "\n",
    "fName = saveFigPath+'/'+MODEL+'_training.txt'\n",
    "with open(fName,'w') as f:\n",
    "    f.write('Training Accuracy\\n')\n",
    "    f.write('Number of features: %d'%X_train_hat.shape[1] +'\\n')\n",
    "    f.write('Residual sum of squares: %.2f' %MSE+'\\n')\n",
    "    f.write('Variance score is: %.2f' %variance_score+'\\n')\n",
    "    f.write('Correlation between predicted ratings and actual ratings is: %.4f'\\\n",
    "            %cor[0,1]+'\\n')  \n",
    "# # Plot prediction vs actual rating.\n",
    "x = predicted_rating\n",
    "y = y_train\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x, y, alpha=0.5)\n",
    "ax.set_xlim((0, 8))\n",
    "ax.set_ylim((0, 8))\n",
    "x0, x1 = ax.get_xlim()\n",
    "y0, y1 = ax.get_ylim()\n",
    "ax.set_aspect(abs(x1-x0)/abs(y1-y0))\n",
    "ax.grid(b=True, which='major', color='k', linestyle='--')\n",
    "m, b = np.polyfit(x, y, 1)\n",
    "X_plot = np.linspace(ax.get_xlim()[0],ax.get_xlim()[1],100)\n",
    "plt.plot(X_plot, m*X_plot + b, '-r')\n",
    "plt.xlabel('Predicted Ratings',fontsize = 26)\n",
    "plt.ylabel('Actual Ratings',fontsize = 26)\n",
    "plt.title('Predicted VS Actual Ratings',fontsize = 26)\n",
    "plt.savefig(saveFigPath+'/'+MODEL+'_predVsActual.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# k-fold#\n",
    "from sklearn.cross_validation import KFold\n",
    "imgNum = feature_transf.shape[0]\n",
    "foldNum = 20\n",
    "kf = KFold(imgNum, n_folds=foldNum, shuffle=True)\n",
    "print(kf)\n",
    "\n",
    "corrList = []\n",
    "varList = []\n",
    "mseList = []\n",
    "feature_new = feature_transf[:,:optNumFea]\n",
    "for train_index, test_index in kf:\n",
    "    feature_train, feature_test = feature_new[train_index], feature_new[test_index]\n",
    "    rating_train, rating_test = mean_rating[train_index], mean_rating[test_index]\n",
    "    \n",
    "    # Do linear regression on feature_arr and mean_rating\n",
    "    regr = linear_model.LinearRegression(fit_intercept=True)\n",
    "    regr.fit(feature_train, rating_train)\n",
    "    predicted_rating = regr.predict(feature_test)\n",
    "\n",
    "    # Calculate the mean square error\n",
    "    MSE = np.mean((predicted_rating - rating_test) ** 2)\n",
    "    mseList.append(MSE)\n",
    "    \n",
    "    # Returns the coefficient of determination R^2 of the prediction.\n",
    "    variance_score = regr.score(feature_test, rating_test)\n",
    "    varList.append(variance_score)\n",
    "    \n",
    "    # Calculate the correlation between prediction and actual rating.\n",
    "    cor = np.corrcoef(predicted_rating, rating_test)\n",
    "    corrList.append(cor[0,1])\n",
    "    \n",
    "print 'Residual sum of squares: %.2f' % (sum(mseList)/foldNum)\n",
    "print 'Variance score is: %.2f' % (sum(varList)/foldNum)\n",
    "print 'Correlation between predicted ratings and actual ratings is: %.4f'%(sum(corrList)/foldNum)\n",
    "\n",
    "fName = saveFigPath+'/'+MODEL+'_kFold.txt'\n",
    "with open(fName,'w') as f:\n",
    "    f.write('Number of folds: %d' % foldNum +'\\n')\n",
    "    f.write('Residual sum of squares: %.2f' % (sum(mseList)/foldNum)+'\\n')\n",
    "    f.write('Variance score is: %.2f' % (sum(varList)/foldNum)+'\\n')\n",
    "    f.write('Correlation between predicted ratings and actual ratings is: %.4f'\\\n",
    "            %(sum(corrList)/foldNum)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "np.savetxt(saveFigPath+'/feature_pca_atrr.csv', feature_new, delimiter=',')\n",
    "#np.savetxt(saveFigPath+'/feature_atrr.csv',featureMat,delimiter = ',')\n",
    "if Dataset == 'twin':\n",
    "    img_index_name_map = dict()\n",
    "    for key in img_type_list.keys():\n",
    "        img_index_name_map[img_type_index[key]] = img_type_list[key]\n",
    "    with open('../Result/'+Dataset+'/attr_imgIndex_name.pickle', 'wb') as handle:\n",
    "        pickle.dump(img_index_name_map, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
