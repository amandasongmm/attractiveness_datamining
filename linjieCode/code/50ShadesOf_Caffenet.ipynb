{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2207\n",
      "(2207, 4592)\n",
      "mean-subtracted values: [('B', 104.0069879317889), ('G', 116.66876761696767), ('R', 122.6789143406786)]\n",
      "Defining the net!\n",
      "conv1\t(96, 3, 11, 11) (96,)\n",
      "conv2\t(256, 48, 5, 5) (256,)\n",
      "conv3\t(384, 256, 3, 3) (384,)\n",
      "conv4\t(384, 192, 3, 3) (384,)\n",
      "conv5\t(256, 192, 3, 3) (256,)\n",
      "fc6\t(4096, 9216) (4096,)\n",
      "fc7\t(4096, 4096) (4096,)\n",
      "fc8\t(1000, 4096) (1000,)\n",
      "4096\n",
      "2207\n"
     ]
    }
   ],
   "source": [
    "# Make sure that caffe is on the python path:\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.decomposition import PCA as sklearnPCA\n",
    "landMarks = pd.read_csv('../../processing/landmarking/mit/mitLandmarks.csv',index_col = 0)\n",
    "imageList = list(set(landMarks.index.tolist()))\n",
    "imageList.sort()\n",
    "imList = [im[3:] for im in imageList]\n",
    "print len(imList)\n",
    "Dataset = 'mit'\n",
    "MODEL = 'geometric'\n",
    "homePath = '/home/lli-ms/'\n",
    "allGeometric = np.loadtxt(homePath+'/features/'+MODEL+'_geometric_'+Dataset+\\\n",
    "           '_totalFeatures.csv', delimiter=',')\n",
    "print allGeometric.shape\n",
    "\n",
    "caffe_root = homePath+'caffe/'\n",
    "pretrained_model_root = homePath+'caffe/'\n",
    "\n",
    "# run this line one time only!\n",
    "import sys\n",
    "caffePython = pretrained_model_root + 'python'\n",
    "if caffePython not in sys.path:\n",
    "    sys.path.insert(0, caffePython)\n",
    "\n",
    "import caffe\n",
    "# Load mean\n",
    "mu = np.load(caffe_root + 'python/caffe/imagenet/ilsvrc_2012_mean.npy')\n",
    "mu = mu.mean(1).mean(1)  # average over pixels to obtain the mean (BGR) pixel values\n",
    "print 'mean-subtracted values:', zip('BGR', mu)\n",
    "\n",
    "# Load the trained net\n",
    "MODEL = 'caffeNet' #'caffeNet','vgg16','vggFace' or 'faceSNN'\n",
    "    \n",
    "MODEL_FILE = caffe_root + 'models/bvlc_reference_caffenet/deploy.prototxt'\n",
    "PRETRAINED_FILE = caffe_root + 'models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel'\n",
    "\n",
    "caffe.set_device(1)\n",
    "caffe.set_mode_gpu()\n",
    "if not os.path.isfile(PRETRAINED_FILE):\n",
    "    print(\"No caffemodel!!!\")\n",
    "elif not os.path.isfile(MODEL_FILE):\n",
    "    print(\"No MODEL !!!\")\n",
    "else:\n",
    "    print \"Defining the net!\"\n",
    "    net = caffe.Net(MODEL_FILE,\n",
    "                PRETRAINED_FILE,\n",
    "                caffe.TEST)\n",
    "# input preprocessing: 'data' is the name of the input blob == net.inputs[0]\n",
    "transformer = caffe.io.Transformer({'data': net.blobs['data'].data.shape})\n",
    "if MODEL != 'faceSNN':\n",
    "    # subtract the dataset-mean value in each channel\n",
    "    transformer.set_mean('data', mu)\n",
    "for layer_name, param in net.params.iteritems():\n",
    "    print layer_name + '\\t' + str(param[0].data.shape), str(param[1].data.shape)\n",
    "transformer.set_transpose('data', (2,0,1))\n",
    "# the reference model operates on images in [0,255] range instead of [0,1]\n",
    "transformer.set_raw_scale('data', 255) \n",
    "# the reference model has channels in BGR order instead of RGB\n",
    "transformer.set_channel_swap('data', (2,1,0))\n",
    "if MODEL == 'caffeNet':\n",
    "    imgeReshape = [227,227]\n",
    "    featureLayer = 'fc7'\n",
    "if 'fc' in featureLayer:\n",
    "    featureNum = net.params[featureLayer][1].data.shape[0]\n",
    "else:\n",
    "    featureNum = net.blobs[featureLayer].data.flatten().shape[0]/net.blobs[featureLayer].data.shape[0]\n",
    "print featureNum\n",
    "features = np.zeros([len(imList),featureNum])\n",
    "totalNum = 0\n",
    "\n",
    "# print len(imList)\n",
    "for img in imList:\n",
    "    imgName = os.path.basename(img)\n",
    "    if imgName.endswith(('.jpg','.png')):\n",
    "        input_image = caffe.io.load_image(img)\n",
    "        net.blobs['data'].reshape(1,3,imgeReshape[0],imgeReshape[1])\n",
    "        net.blobs['data'].data[...] = transformer.preprocess('data', input_image)\n",
    "        out = net.forward()\n",
    "        feat = net.blobs[featureLayer].data\n",
    "        if Dataset =='twin':\n",
    "            img_type = int(imgName[7:-4])/perImNum\n",
    "            img_index = int(imgName[7:-4])%perImNum\n",
    "            #print 'img_type:',img_type\n",
    "            if img_type in img_type_num.keys():\n",
    "                img_type_num[img_type] = img_type_num[img_type] + 1\n",
    "                img_type_list[img_type][img_index] = img\n",
    "            else:\n",
    "                img_type_num[img_type] = 0\n",
    "                img_type_list[img_type] = [None]*perImNum\n",
    "                img_type_index[img_type] = type_index\n",
    "                type_index +=1\n",
    "            #print 'img_type_index:',img_type_index[img_type]\n",
    "            features[img_type_index[img_type],img_type_num[img_type]] = feat.flatten()\n",
    "        else:\n",
    "            # need to be further revised!\n",
    "            features[totalNum] = feat.flatten()\n",
    "            #print features[totalNum]\n",
    "        totalNum +=1\n",
    "    else:\n",
    "        print img\n",
    "#print len(img_type_num)\n",
    "print totalNum\n",
    "caffe_Feature = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2206\n",
      "(353, 4096) (1413, 4096) (441, 4096)\n",
      "The number of PCs needed to retain 700.000 variance is 700.\n",
      "(700, 4096)\n",
      "(1413, 700)\n",
      "(441, 700)\n",
      "atypical\n",
      "mean rating:  4.08446414454\n",
      "Correlation:  0.318188987945\n",
      "num of features:  162\n",
      "Spearman Correlation:  0.29519829687\n",
      "num of features:  172\n",
      "R^2 score:  0.0906759948747\n",
      "num of features:  81\n",
      "MSE:  0.435127808225\n",
      "num of features:  81\n",
      "**************************Result of train and test**************************************\n",
      "number of features: 162\n",
      "On test set:\n",
      "Residual sum of squares: 0.43\n",
      "Variance score is: 0.05\n",
      "Correlation between predicted ratings and actual ratings is: 0.2903\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.2979\n",
      " \n",
      "On training set:\n",
      "Residual sum of squares: 0.33\n",
      "Variance score is: 0.28\n",
      "Correlation between predicted ratings and actual ratings is: 0.5320\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.5136\n",
      "****************************************************************************************\n",
      "boring\n",
      "mean rating:  4.28997636656\n",
      "Correlation:  0.541633738707\n",
      "num of features:  66\n",
      "Spearman Correlation:  0.538485296313\n",
      "num of features:  66\n",
      "R^2 score:  0.292663401213\n",
      "num of features:  66\n",
      "MSE:  0.493228316927\n",
      "num of features:  66\n",
      "**************************Result of train and test**************************************\n",
      "number of features: 66\n",
      "On test set:\n",
      "Residual sum of squares: 0.54\n",
      "Variance score is: 0.23\n",
      "Correlation between predicted ratings and actual ratings is: 0.4802\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.4788\n",
      " \n",
      "On training set:\n",
      "Residual sum of squares: 0.42\n",
      "Variance score is: 0.36\n",
      "Correlation between predicted ratings and actual ratings is: 0.6054\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.5985\n",
      "****************************************************************************************\n",
      "calm\n",
      "mean rating:  5.80624816221\n",
      "Correlation:  0.444254248654\n",
      "num of features:  106\n",
      "Spearman Correlation:  0.378221974193\n",
      "num of features:  106\n",
      "R^2 score:  0.195126277082\n",
      "num of features:  106\n",
      "MSE:  0.425184507438\n",
      "num of features:  106\n",
      "**************************Result of train and test**************************************\n",
      "number of features: 106\n",
      "On test set:\n",
      "Residual sum of squares: 0.41\n",
      "Variance score is: 0.15\n",
      "Correlation between predicted ratings and actual ratings is: 0.3928\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.3069\n",
      " \n",
      "On training set:\n",
      "Residual sum of squares: 0.38\n",
      "Variance score is: 0.27\n",
      "Correlation between predicted ratings and actual ratings is: 0.5236\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.4360\n",
      "****************************************************************************************\n",
      "cold\n",
      "mean rating:  3.71738235795\n",
      "Correlation:  0.681698218227\n",
      "num of features:  459\n",
      "Spearman Correlation:  0.643161404208\n",
      "num of features:  298\n",
      "R^2 score:  0.46293438071\n",
      "num of features:  298\n",
      "MSE:  0.826205567816\n",
      "num of features:  298\n",
      "**************************Result of train and test**************************************\n",
      "number of features: 459\n",
      "On test set:\n",
      "Residual sum of squares: 0.77\n",
      "Variance score is: 0.47\n",
      "Correlation between predicted ratings and actual ratings is: 0.6972\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.6609\n",
      " \n",
      "On training set:\n",
      "Residual sum of squares: 0.43\n",
      "Variance score is: 0.73\n",
      "Correlation between predicted ratings and actual ratings is: 0.8559\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.8091\n",
      "****************************************************************************************\n",
      "common\n",
      "mean rating:  5.32550588808\n"
     ]
    }
   ],
   "source": [
    "for j in range(1,50): \n",
    "    import random\n",
    "    featureMat = caffe_Feature\n",
    "    randomInd = range(featureMat.shape[0])\n",
    "    random.shuffle(randomInd)\n",
    "    print max(randomInd)\n",
    "    featureMat = featureMat[randomInd,:]\n",
    "    nSamples = featureMat.shape[0]\n",
    "    testRatio = 0.2\n",
    "    valiRatio = 0.2\n",
    "    testFeatures = featureMat[:int(nSamples*testRatio),:]\n",
    "    trainFeatures = featureMat[int(nSamples*testRatio):,:]\n",
    "    valiFeatures = featureMat[-int(trainFeatures.shape[0]*valiRatio):,:]\n",
    "    trainFeatures = trainFeatures[:-int(trainFeatures.shape[0]*valiRatio),:]\n",
    "    print valiFeatures.shape, trainFeatures.shape, testFeatures.shape\n",
    "    explained_variance = 700\n",
    "    sklearn_pca = sklearnPCA(n_components=explained_variance, whiten  = True)\n",
    "    trainfeature_transf = sklearn_pca.fit_transform(trainFeatures)\n",
    "    print 'The number of PCs needed to retain %.3f variance is %d.' \\\n",
    "          % (explained_variance, trainfeature_transf.shape[1])\n",
    "    print sklearn_pca.components_.shape\n",
    "    print trainfeature_transf.shape\n",
    "    testfeature_tansf = sklearn_pca.transform(testFeatures)\n",
    "    print testfeature_tansf.shape\n",
    "    valifeature_transf = sklearn_pca.transform(valiFeatures)\n",
    "\n",
    "    radomImlist = np.asarray(imList)[randomInd]\n",
    "\n",
    "\n",
    "    modelList = []\n",
    "    optFeaNumList = []\n",
    "\n",
    "    import sys\n",
    "    import pandas as pd\n",
    "    socialMeasures = '../Result/mit/socialMeasures.csv'\n",
    "    socialMeasures = pd.read_csv(socialMeasures,index_col = 0)\n",
    "    socialAttr = socialMeasures.columns.tolist()\n",
    "    delElement = ['subage.1', 'submale.1', 'subrace.1','subage', 'submale',\\\n",
    "                  'subrace','catch', 'catchAns','catch.1','catchAns.1']\n",
    "    social2Attr = [x for x in socialAttr if x not in delElement]\n",
    "\n",
    "    PkgPath = homePath+'attractiveness_datamining/linjieCode/code'\n",
    "    fName = \"../Result/CaffeNet/regression_result_fc7_\"+str(j)+\".csv\"\n",
    "    text_file = open(fName, \"w\")\n",
    "    d = 'Social Attributes, caffeNet_test, caffeNet_train, caffeNet_FeatureNum'+'\\n'\n",
    "    text_file.write(d)\n",
    "\n",
    "    if PkgPath not in sys.path:\n",
    "        sys.path.insert(0, PkgPath)\n",
    "    #print sys.path\n",
    "    from xVal_train_test import Train_Test\n",
    "\n",
    "    import sklearn\n",
    "    import numpy as np\n",
    "    fullRating = np.zeros((2207,40))\n",
    "    for attr in social2Attr:\n",
    "        print attr\n",
    "        #attr= social2Attr[9]ï¼Œ\n",
    "        mean_rating = [socialMeasures.loc[imList[i][31:],attr] for i in range(len(imList))\\\n",
    "                   if imList[i][31:] in socialMeasures.index]\n",
    "        mean_rating = map(float, mean_rating)\n",
    "        mean_rating = np.array(mean_rating)\n",
    "        radomRating = mean_rating[randomInd]\n",
    "        testRating = radomRating[:int(nSamples*testRatio)]\n",
    "        trainRating = radomRating[int(nSamples*testRatio):]\n",
    "        valiRating = radomRating[-int(trainRating.shape[0]*valiRatio):]\n",
    "        trainSubRating = trainRating[:-int(trainRating.shape[0]*valiRatio)]\n",
    "\n",
    "        baseLine = mean_rating.mean()\n",
    "        print 'mean rating: ', baseLine\n",
    "\n",
    "        predictionModel = sklearn.linear_model.RidgeCV(alphas=np.logspace(-3,2,num=20), fit_intercept=True)\n",
    "        myModel,optFeaNum,testC,trainC = Train_Test(trainSubRating,testRating,valiRating,trainfeature_transf, \\\n",
    "                                       testfeature_tansf,valifeature_transf,xVal = True,numTrain = 1,\\\n",
    "                                       pModel = predictionModel,getMaxMin = False,MODEL= MODEL, \\\n",
    "                                       plotPredActual = False,returnModel = True,returnValTrain = True)\n",
    "        modelList.append(myModel)\n",
    "        optFeaNumList.append(optFeaNum)\n",
    "        \n",
    "       \n",
    "        d = attr+', '+ str(testC)+', '+str(trainC)+', '+str(optFeaNum)+'\\n'\n",
    "        text_file.write(d)\n",
    "    text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = np.zeros((40,3))\n",
    "for j in range(1,50): \n",
    "    fName = \"../Result/CaffeNet/regression_result_fc7_\"+str(j)+\".csv\"\n",
    "    df = pd.read_csv(fName,index_col = 0)\n",
    "    result += df.as_matrix()\n",
    "result = result/49\n",
    "result_df = pd.DataFrame(result,              \n",
    "                         index=df.index,\n",
    "                         columns=df.columns)\n",
    "result_df.to_csv('../Result/CaffeNet/combined_result_fc7.csv')\n",
    "print result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "totalRating = np.concatenate([trainSubRating,valiRating,testRating])\n",
    "print totalRating.shape\n",
    "totalFeature = np.concatenate([trainfeature_transf_vgg[:,:optFeaNum_vgg],valifeature_transf_vgg[:,:optFeaNum_vgg],\\\n",
    "                               testfeature_tansf_vgg[:,:optFeaNum_vgg]])\n",
    "print totalFeature.shape\n",
    "fullRating[:,social2Attr.index(attr)] = myModel_vgg.predict(totalFeature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
