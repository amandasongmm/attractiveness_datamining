{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "landMarks = pd.read_csv('../../processing/landmarking/mit/mitLandmarks.csv',index_col = 0)\n",
    "imageList = list(set(landMarks.index.tolist()))\n",
    "imageList.sort()\n",
    "X_LMmatrix = np.zeros((len(imageList),68))\n",
    "Y_LMmatrix = np.zeros((len(imageList),68))\n",
    "\n",
    "# x = landMarks.ix[images[0]].x.tolist()\n",
    "# print x\n",
    "imList = imageList\n",
    "\n",
    "for im in imageList:\n",
    "    ind_im = imageList.index(im)\n",
    "    imList[ind_im] = im[3:]\n",
    "    X_LMmatrix[ind_im,:] = landMarks.ix[im].x.tolist()\n",
    "    Y_LMmatrix[ind_im,:] = landMarks.ix[im].y.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import colorsys\n",
    "import random\n",
    "# print Rectangle((someX, someY), yLength, yLength*0.5)\n",
    "def get3RegionRect(X_LMmatrix,Y_LMmatrix, imInd):\n",
    "    yLengthArr = []\n",
    "    xLengthArr = []\n",
    "    someX_Arr = []\n",
    "    someY_Arr = []\n",
    "    #left patch\n",
    "    yLengthArr.append(Y_LMmatrix[imInd,4]-Y_LMmatrix[imInd,3])\n",
    "    xLengthArr.append((X_LMmatrix[imInd,48]-X_LMmatrix[imInd,2])/2)\n",
    "    someX_Arr.append((X_LMmatrix[imInd,48]+X_LMmatrix[imInd,3])/2-xLengthArr[0]/2) \n",
    "    someY_Arr.append((Y_LMmatrix[imInd,2]+Y_LMmatrix[imInd,29])/2-yLengthArr[0]/2)\n",
    "    #right patch\n",
    "    yLengthArr.append(Y_LMmatrix[imInd,12]-Y_LMmatrix[imInd,13])\n",
    "    xLengthArr.append((X_LMmatrix[imInd,12]-X_LMmatrix[imInd,54])/2)\n",
    "    someX_Arr.append((X_LMmatrix[imInd,54]+X_LMmatrix[imInd,13])/2-xLengthArr[1]/2) \n",
    "    someY_Arr.append((Y_LMmatrix[imInd,29]+Y_LMmatrix[imInd,14])/2-yLengthArr[1]/2)\n",
    "    #top patch\n",
    "    yLengthArr.append((X_LMmatrix[imInd,22]-X_LMmatrix[imInd,21])/2)\n",
    "    xLengthArr.append(X_LMmatrix[imInd,22]-X_LMmatrix[imInd,21])\n",
    "    someX_Arr.append((X_LMmatrix[imInd,21]+X_LMmatrix[imInd,22])/2-xLengthArr[2]/2) \n",
    "    someY_Arr.append((Y_LMmatrix[imInd,21]+Y_LMmatrix[imInd,22])/2-yLengthArr[2]/2)\n",
    "    return someX_Arr, someY_Arr, xLengthArr, yLengthArr\n",
    "\n",
    "def findAllCoors(someX, someY, xLength, yLength):\n",
    "    Xmatrix = np.zeros((int(xLength),int(yLength)))\n",
    "    Ymatrix = np.zeros((int(xLength),int(yLength)))\n",
    "    for i in range(int(xLength)):\n",
    "        for j in range(int(yLength)):\n",
    "            Xmatrix[i,j] = int(someX)+i\n",
    "            Ymatrix[i,j] = int(someY)+j\n",
    "    return Xmatrix,Ymatrix\n",
    "\n",
    "def getAveColor (someX, someY, xLength, yLength, imageName):\n",
    "    im = Image.open(imageName)\n",
    "    rgb_im = im.convert('RGB')\n",
    "    Xmatrix,Ymatrix = findAllCoors(someX, someY, xLength, yLength) \n",
    "    Xsize, Ysize = Xmatrix.shape\n",
    "    hValue = np.zeros((Xsize, Ysize))\n",
    "    sValue = np.zeros((Xsize, Ysize))\n",
    "    vValue = np.zeros((Xsize, Ysize))\n",
    "    for i in range(Xsize):\n",
    "        for j in range (Ysize):\n",
    "            r, g, b = rgb_im.getpixel((Xmatrix[i,j],Ymatrix[i,j]))\n",
    "            hValue[i,j],sValue[i,j],vValue[i,j] = colorsys.rgb_to_hsv(r/255.0, g/255.0, b/255.0)\n",
    "    return [hValue.mean(),sValue.mean(),vValue.mean()]\n",
    "\n",
    "rand_int = imList.index(random.choice(imList))\n",
    "meanHSV = np.zeros((len(imList), 3))\n",
    "for imInd in range(len(imList)):\n",
    "    someX_Arr, someY_Arr, xLengthArr, yLengthArr = get3RegionRect(X_LMmatrix,Y_LMmatrix, imInd)\n",
    "    tempMean = np.zeros((1,3))\n",
    "    for j in range(len(someX_Arr)):\n",
    "        tempMean += np.asarray(getAveColor(someX_Arr[j], someY_Arr[j], xLengthArr[j], yLengthArr[j], imList[imInd]))\n",
    "    meanHSV[imInd,:] = tempMean/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H mean:  0.101154218545 , S mean:  0.392194580956 , V mean:  0.767811662084\n",
      "H std:  0.162586053503 , S std:  0.114747951156 , V std:  0.115534603901\n"
     ]
    }
   ],
   "source": [
    "print 'H mean: ', meanHSV[:,0].mean(),', S mean: ', meanHSV[:,1].mean(), ', V mean: ', meanHSV[:,2].mean()\n",
    "print 'H std: ', meanHSV[:,0].std(),', S std: ', meanHSV[:,1].std(),', V std: ', meanHSV[:,2].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smoothness mean:  36.3988823441 , smoothness std:  26.1724793184\n"
     ]
    }
   ],
   "source": [
    "from skimage import feature, color, io\n",
    "# Compute the Canny filter for two values of sigma\n",
    "def getSmoothness(imageName, someX_Arr, someY_Arr, xLengthArr, yLengthArr, ifPlot = False,sigma=1):\n",
    "    BigImage = color.rgb2gray(io.imread(imageName))\n",
    "    edged = feature.canny(BigImage, sigma = sigma)\n",
    "    #print BigImage.shape\n",
    "    if ifPlot:\n",
    "        fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(6, 3), sharex=True, sharey=True)\n",
    "\n",
    "        ax1.imshow(BigImage, cmap=plt.cm.gray)\n",
    "        ax1.axis('off')\n",
    "        ax1.set_title('original image', fontsize=20)\n",
    "\n",
    "        ax2.imshow(edged, cmap=plt.cm.gray)\n",
    "        ax2.axis('off')\n",
    "        ax2.set_title('Canny filter, $\\sigma='+str(sigma)+'$', fontsize=20)\n",
    "\n",
    "        fig.subplots_adjust(wspace=0.02, hspace=0.02, top=0.9,\n",
    "                            bottom=0.02, left=0.02, right=0.98)\n",
    "        plt.show()\n",
    "    aveEdgeNum = 0.0\n",
    "    for j in range(len(someX_Arr)):\n",
    "        image = BigImage[int(someY_Arr[j]):int(someY_Arr[j]+yLengthArr[j])\\\n",
    "                  ,int(someX_Arr[j]):int(someX_Arr[j]+xLengthArr[j])]\n",
    "        edged = feature.canny(image, sigma = sigma)\n",
    "        if ifPlot:\n",
    "            fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(6, 3), sharex=True, sharey=True)\n",
    "\n",
    "            ax1.imshow(image, cmap=plt.cm.gray)\n",
    "            ax1.axis('off')\n",
    "            ax1.set_title('original image', fontsize=20)\n",
    "\n",
    "            ax2.imshow(edged, cmap=plt.cm.gray)\n",
    "            ax2.axis('off')\n",
    "            ax2.set_title('Canny filter, $\\sigma='+str(sigma)+'$', fontsize=20)\n",
    "\n",
    "            fig.subplots_adjust(wspace=0.02, hspace=0.02, top=0.9,\n",
    "                                bottom=0.02, left=0.02, right=0.98)\n",
    "            plt.show()\n",
    "        aveEdgeNum += edged.sum()\n",
    "        #print image.shape\n",
    "    aveEdgeNum /=float(len(someX_Arr))\n",
    "    return aveEdgeNum\n",
    "smoothness = np.zeros((len(imList),1))\n",
    "custom_sigma = 0.33\n",
    "ifPlot = False\n",
    "for imInd in range(len(imList)):\n",
    "    someX_Arr, someY_Arr, xLengthArr, yLengthArr = get3RegionRect(X_LMmatrix,Y_LMmatrix, imInd)\n",
    "    #print someX_Arr, someY_Arr, xLengthArr, yLengthArr\n",
    "    smoothness[imInd] = \\\n",
    "    getSmoothness(imList[imInd], someX_Arr, someY_Arr, xLengthArr, yLengthArr,sigma=custom_sigma,ifPlot = ifPlot)\n",
    "\n",
    "print 'smoothness mean: ',smoothness.mean(),', smoothness std: ', smoothness.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'FA', u'CA', u'AV', u'h', u's', u'v', u'smoothness'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# save as a csv\n",
    "from pandas import DataFrame\n",
    "data = np.concatenate((meanHSV,smoothness), axis=1)\n",
    "geometric = pd.read_csv('../../MIT2kFaceDataset/clean_data/geometric_all.csv',index_col = 0)\n",
    "df = DataFrame(data,columns=['h', 's', 'v', 'smoothness'])\n",
    "config_feature = geometric.loc[:,'nose_width':'AV']\n",
    "config_feature = pd.concat([config_feature,df], axis=1)\n",
    "not_measure_feature = config_feature.loc[:,'FA':'smoothness']\n",
    "print not_measure_feature.columns\n",
    "config_feauture = config_feature.as_matrix()\n",
    "not_measure_feature = not_measure_feature.as_matrix()\n",
    "df = pd.concat([geometric,df], axis=1)\n",
    "df.to_csv('../../MIT2kFaceDataset/clean_data/geometric_wSmoothness.csv',index = False)\n",
    "df = pd.read_csv('../../MIT2kFaceDataset/clean_data/geometric_wSmoothness.csv',index_col = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def computeDist(X_LMmatrix,Y_LMmatrix, imInd):\n",
    "    pointNum = X_LMmatrix.shape[1]\n",
    "    distArr = np.zeros((1,pointNum*(pointNum-1)/2))\n",
    "    distInd = 0\n",
    "    for i in range(pointNum):\n",
    "        for j in range(i+1,pointNum):\n",
    "            x1 = np.asarray([X_LMmatrix[imInd,i],Y_LMmatrix[imInd,i]])\n",
    "            x2 = np.asarray([X_LMmatrix[imInd,j],Y_LMmatrix[imInd,j]])\n",
    "            distArr[0,distInd] = np.linalg.norm(x1-x2)\n",
    "            distInd +=1\n",
    "    return distArr\n",
    "import sys\n",
    "def computeSlope(X_LMmatrix,Y_LMmatrix, imInd):\n",
    "    pointNum = X_LMmatrix.shape[1]\n",
    "    slopeArr = np.zeros((1,pointNum*(pointNum-1)/2))\n",
    "    slopeInd = 0\n",
    "    for i in range(pointNum):\n",
    "        for j in range(i+1,pointNum):\n",
    "            denominator = float(X_LMmatrix[imInd,i]-X_LMmatrix[imInd,j])\n",
    "            if denominator != 0:\n",
    "                slopeArr[0,slopeInd] = float(Y_LMmatrix[imInd,i]-Y_LMmatrix[imInd,j])/denominator\n",
    "            else:\n",
    "                #print i,j\n",
    "                if float(Y_LMmatrix[imInd,i]-Y_LMmatrix[imInd,j]) > 0:\n",
    "                    slopeArr[0,slopeInd] = sys.float_info.max/100000\n",
    "                elif float(Y_LMmatrix[imInd,i]-Y_LMmatrix[imInd,j]) ==0:\n",
    "                    slopeArr[0,slopeInd] = 0\n",
    "                else:\n",
    "                    slopeArr[0,slopeInd] = -sys.float_info.max/100000\n",
    "            slopeInd +=1\n",
    "    return slopeArr\n",
    "def computeCosine(X_LMmatrix,Y_LMmatrix, imInd):\n",
    "    pointNum = X_LMmatrix.shape[1]\n",
    "    cosineArr = np.zeros((1,pointNum*(pointNum-1)/2))\n",
    "    cosineInd = 0\n",
    "    for i in range(pointNum):\n",
    "        for j in range(i+1,pointNum):\n",
    "            denominator = float(X_LMmatrix[imInd,i]-X_LMmatrix[imInd,j])\n",
    "            if denominator != 0:\n",
    "                cosineArr[0,cosineInd] = np.cos(np.arctan(float(Y_LMmatrix[imInd,i]-Y_LMmatrix[imInd,j])/denominator))\n",
    "            else:\n",
    "                cosineArr[0,cosineInd] = 0\n",
    "            cosineInd +=1\n",
    "    return cosineArr\n",
    "\n",
    "\n",
    "distMat = np.zeros((len(imList),X_LMmatrix.shape[1]*(X_LMmatrix.shape[1]-1)/2))\n",
    "slopeMat = np.zeros((len(imList),X_LMmatrix.shape[1]*(X_LMmatrix.shape[1]-1)/2))\n",
    "for imInd in range(len(imList)):\n",
    "    distArr = computeDist(X_LMmatrix,Y_LMmatrix, imInd)\n",
    "    slopeArr = computeCosine(X_LMmatrix,Y_LMmatrix, imInd)\n",
    "    distMat[imInd,:] = distArr\n",
    "    slopeMat[imInd,:] = slopeArr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of PCs needed to retain 2207.000 variance is 2207.\n",
      "The number of PCs needed to retain 2207.000 variance is 2207.\n",
      "The number of PCs needed to retain 2207.000 variance is 2207.\n"
     ]
    }
   ],
   "source": [
    "distSlope = np.concatenate((slopeMat,distMat), axis=1)\n",
    "allGeometric = np.concatenate((config_feature,distSlope),axis = 1)\n",
    "only_w_pixel = np.concatenate((meanHSV,smoothness,distSlope),axis = 1)\n",
    "\n",
    "from sklearn.decomposition import PCA as sklearnPCA\n",
    "explained_variance = distSlope.shape[0]\n",
    "sklearn_pca = sklearnPCA(n_components=explained_variance, whiten = True)\n",
    "distSlope_transf = sklearn_pca.fit_transform(distSlope)\n",
    "print 'The number of PCs needed to retain %.3f variance is %d.' \\\n",
    "      % (explained_variance, distSlope_transf.shape[1])\n",
    "\n",
    "sklearn_pca = sklearnPCA(n_components=explained_variance, whiten = True)\n",
    "allGeometric_transf = sklearn_pca.fit_transform(allGeometric)\n",
    "print 'The number of PCs needed to retain %.3f variance is %d.' \\\n",
    "      % (explained_variance, allGeometric_transf.shape[1])\n",
    "    \n",
    "sklearn_pca = sklearnPCA(n_components=explained_variance, whiten = True)\n",
    "only_w_pixel_transf = sklearn_pca.fit_transform(only_w_pixel)\n",
    "print 'The number of PCs needed to retain %.3f variance is %d.' \\\n",
    "      % (explained_variance, only_w_pixel_transf.shape[1])\n",
    "\n",
    "config_distPCA = np.concatenate((config_feature,distSlope_transf),axis = 1)\n",
    "dist_slope_nonConfig = np.concatenate((not_measure_feature,distSlope_transf),axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2207\n",
      "mean rating:  4.93915489035\n",
      "62\n",
      "0.535707226033\n"
     ]
    }
   ],
   "source": [
    "mean_rating = geometric.attractive.as_matrix()\n",
    "print len(mean_rating)\n",
    "mean_rating = map(float, mean_rating)\n",
    "mean_rating = np.array(mean_rating)\n",
    "import sys\n",
    "#print sys.path\n",
    "# local\n",
    "PkgPath = '/Users/Olivialinlin/Documents/Github/attractiveness_datamining/linjieCode/code'\n",
    "# server\n",
    "# PkgPath = '/home/lli-ms/attractiveness_datamining/linjieCode/code'\n",
    "\n",
    "if PkgPath not in sys.path:\n",
    "    sys.path.insert(0, PkgPath)\n",
    "#print sys.path\n",
    "from xVal_train_test import Train_Test\n",
    "\n",
    "baseLine = mean_rating.mean()\n",
    "print 'mean rating: ', baseLine\n",
    "import sklearn\n",
    "numFeatureArr = np.linspace(1,1000,num =50 ,dtype = np.int16)\n",
    "valCorr = []\n",
    "trainCorr = []\n",
    "for numFeature in numFeatureArr:\n",
    "    predictionModel = sklearn.linear_model.RidgeCV(alphas=np.logspace(-3,2,num=20), fit_intercept=True)\n",
    "    valC, trainC = Train_Test(mean_rating,distSlope_transf, hyperParam = numFeature, xVal = False,\\\n",
    "                              pModel = predictionModel,numTrain = 50,savePath = '../Result/mit',MODEL= 'distSlope')\n",
    "    \n",
    "    valCorr.append(valC)\n",
    "    trainCorr.append(trainC)\n",
    "\n",
    "print numFeatureArr[valCorr.index(max(valCorr))]\n",
    "print max(valCorr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n",
      "0.541384165364\n"
     ]
    }
   ],
   "source": [
    "numFeatureArr = np.linspace(1,1000,num =50 ,dtype = np.int16)\n",
    "valCorr = []\n",
    "trainCorr = []\n",
    "for numFeature in numFeatureArr:\n",
    "    predictionModel = sklearn.linear_model.RidgeCV(alphas=np.logspace(-3,2,num=20), fit_intercept=True)\n",
    "    valC, trainC = Train_Test(mean_rating,only_w_pixel_transf, hyperParam = numFeature, xVal = False,\\\n",
    "                              pModel = predictionModel,numTrain = 50,savePath = '../Result/mit',MODEL= 'distSlope')\n",
    "    \n",
    "    valCorr.append(valC)\n",
    "    trainCorr.append(trainC)\n",
    "\n",
    "print numFeatureArr[valCorr.index(max(valCorr))]\n",
    "print max(valCorr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n",
      "0.544528682057\n"
     ]
    }
   ],
   "source": [
    "numFeatureArr = np.linspace(1,1000,num =50 ,dtype = np.int16)\n",
    "valCorr = []\n",
    "trainCorr = []\n",
    "for numFeature in numFeatureArr:\n",
    "    predictionModel = sklearn.linear_model.RidgeCV(alphas=np.logspace(-3,2,num=20), fit_intercept=True)\n",
    "    valC, trainC = Train_Test(mean_rating,allGeometric_transf, hyperParam = numFeature, xVal = False,\\\n",
    "                              pModel = predictionModel,numTrain = 50,savePath = '../Result/mit',MODEL= 'distSlope')\n",
    "    \n",
    "    valCorr.append(valC)\n",
    "    trainCorr.append(trainC)\n",
    "\n",
    "print numFeatureArr[valCorr.index(max(valCorr))]\n",
    "print max(valCorr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98\n",
      "0.549999425054\n"
     ]
    }
   ],
   "source": [
    "numFeatureArr = np.linspace(40,1000,num =50 ,dtype = np.int16)\n",
    "valCorr = []\n",
    "trainCorr = []\n",
    "for numFeature in numFeatureArr:\n",
    "    predictionModel = sklearn.linear_model.RidgeCV(alphas=np.logspace(-3,2,num=20), fit_intercept=True)\n",
    "    valC, trainC = Train_Test(mean_rating,config_distPCA, hyperParam = numFeature, xVal = False,\\\n",
    "                              pModel = predictionModel,numTrain = 50,savePath = '../Result/mit',MODEL= 'distSlope')\n",
    "    \n",
    "    valCorr.append(valC)\n",
    "    trainCorr.append(trainC)\n",
    "\n",
    "print numFeatureArr[valCorr.index(max(valCorr))]\n",
    "print max(valCorr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86\n",
      "0.552022666189\n"
     ]
    }
   ],
   "source": [
    "numFeatureArr = np.linspace(5,1000,num =50 ,dtype = np.int16)\n",
    "valCorr = []\n",
    "trainCorr = []\n",
    "for numFeature in numFeatureArr:\n",
    "    predictionModel = sklearn.linear_model.RidgeCV(alphas=np.logspace(-3,2,num=20), fit_intercept=True)\n",
    "    valC, trainC = Train_Test(mean_rating,dist_slope_nonConfig, hyperParam = numFeature, xVal = False,\\\n",
    "                              pModel = predictionModel,numTrain = 50,savePath = '../Result/mit',MODEL= 'distSlope')\n",
    "    \n",
    "    valCorr.append(valC)\n",
    "    trainCorr.append(trainC)\n",
    "\n",
    "print numFeatureArr[valCorr.index(max(valCorr))]\n",
    "print max(valCorr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_designed = dist_slope_nonConfig[:,:86]\n",
    "valC, trainC = Train_Test(mean_rating,dist_slope_nonConfig, hyperParam = numFeature, xVal = False,\\\n",
    "                              pModel = predictionModel,numTrain = 1,savePath = '../Result/mit',MODEL= 'distSlope')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.patches import Rectangle\n",
    "import random\n",
    "#imInd = imList.index(random.choice(imList))\n",
    "im = plt.imread(imList[imInd])\n",
    "fSize = 6\n",
    "implot = plt.imshow(im)\n",
    "import pylab\n",
    "# put a blue dot at (10, 20)\n",
    "plt.scatter(X_LMmatrix[imInd,:],Y_LMmatrix[imInd,:])\n",
    "labels = [str(i) for i in range(68)]\n",
    "for label, x, y in zip(labels, X_LMmatrix[imInd,:], Y_LMmatrix[imInd,:]):\n",
    "    plt.annotate(\n",
    "        label, \n",
    "        xy = (x, y), xytext = (-20, 20),\n",
    "        textcoords = 'offset points', ha = 'right', va = 'bottom',\n",
    "        bbox = dict(boxstyle = 'round,pad=0.5', fc = 'yellow', alpha = 0.5),\n",
    "        arrowprops = dict(arrowstyle = '->', connectionstyle = 'arc3,rad=0'))\n",
    "yLengthArr = []\n",
    "xLengthArr = []\n",
    "someX_Arr = []\n",
    "someY_Arr = []\n",
    "# left patch\n",
    "yLengthArr.append(Y_LMmatrix[imInd,4]-Y_LMmatrix[imInd,3])\n",
    "xLengthArr.append((X_LMmatrix[imInd,48]-X_LMmatrix[imInd,2])/2)\n",
    "someX_Arr.append((X_LMmatrix[imInd,48]+X_LMmatrix[imInd,3])/2-xLength[0]/2) \n",
    "someY_Arr.append((Y_LMmatrix[imInd,2]+Y_LMmatrix[imInd,29])/2-yLength[0]/2)\n",
    "# right patch\n",
    "yLengthArr.append(Y_LMmatrix[imInd,12]-Y_LMmatrix[imInd,13])\n",
    "xLengthArr.append((X_LMmatrix[imInd,12]-X_LMmatrix[imInd,54])/2)\n",
    "someX_Arr.append((X_LMmatrix[imInd,54]+X_LMmatrix[imInd,13])/2-xLength[1]/2) \n",
    "someY_Arr.append((Y_LMmatrix[imInd,29]+Y_LMmatrix[imInd,14])/2-yLength[1]/2)\n",
    "# top patch\n",
    "yLengthArr.append((X_LMmatrix[imInd,22]-X_LMmatrix[imInd,21])/2)\n",
    "xLengthArr.append(X_LMmatrix[imInd,22]-X_LMmatrix[imInd,21])\n",
    "someX_Arr.append((X_LMmatrix[imInd,21]+X_LMmatrix[imInd,22])/2-xLength[2]/2) \n",
    "someY_Arr.append((Y_LMmatrix[imInd,21]+Y_LMmatrix[imInd,22])/2-yLength[2]/2)\n",
    "currentAxis = plt.gca()\n",
    "for i in range(len(xLength)):\n",
    "    currentAxis.add_patch(Rectangle((someX_Arr[i], someY_Arr[i]), xLengthArr[i], yLengthArr[i], facecolor=\"grey\"))\n",
    "    \n",
    "fig = pylab.gcf()\n",
    "fig.set_size_inches(5*fSize, 3*fSize)\n",
    "plt.show()\n",
    "print someX_Arr, someY_Arr, xLengthArr, yLengthArr\n",
    "print X_LMmatrix[imInd,2], Y_LMmatrix[imInd,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "im_Image = Image.open(imList[imInd])\n",
    "rgb_im = im_Image.convert('RGB')\n",
    "r, g, b = rgb_im.getpixel((X_LMmatrix[imInd,1],Y_LMmatrix[imInd,1]))\n",
    "print r,g,b\n",
    "import colorsys\n",
    "h,s,v = colorsys.rgb_to_hsv(r/255.0, g/255.0, b/255.0)\n",
    "print h,s,v\n",
    "\n",
    "print im[int(Y_LMmatrix[imInd,1]),int(X_LMmatrix[imInd,1]),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "img = color.rgb2gray(io.imread(imList[imInd]))\n",
    "smallRegion = img[int(someX_Arr[1]):int(someX_Arr[1]+xLengthArr[1])\\\n",
    "                  ,int(someY_Arr[1]):int(someY_Arr[1]+yLengthArr[1])]\n",
    "#im = smallRegion\n",
    "im = img\n",
    "custom_sigma = 0.33\n",
    "#edges3 = auto_canny(im, sigma = 0.9)\n",
    "edges1 = feature.canny(im)\n",
    "edges2 = feature.canny(im, sigma = custom_sigma)\n",
    "print edges1.sum()\n",
    "print edges2.sum()\n",
    "#print edges3.sum()\n",
    "# display results\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(nrows=1, ncols=3, figsize=(8, 3), sharex=True, sharey=True)\n",
    "\n",
    "ax1.imshow(im, cmap=plt.cm.gray)\n",
    "ax1.axis('off')\n",
    "ax1.set_title('original image', fontsize=20)\n",
    "\n",
    "ax2.imshow(edges1, cmap=plt.cm.gray)\n",
    "ax2.axis('off')\n",
    "ax2.set_title('Canny filter, $\\sigma=1$', fontsize=20)\n",
    "\n",
    "ax3.imshow(edges2, cmap=plt.cm.gray)\n",
    "ax3.axis('off')\n",
    "ax3.set_title('Canny filter, $\\sigma='+str(custom_sigma)+'$', fontsize=20)\n",
    "\n",
    "# ax4.imshow(edges3, cmap=plt.cm.gray)\n",
    "# ax4.axis('off')\n",
    "# ax4.set_title('auto', fontsize=20)\n",
    "\n",
    "fig.subplots_adjust(wspace=0.02, hspace=0.02, top=0.9,\n",
    "                    bottom=0.02, left=0.02, right=0.98)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage.filters import roberts, sobel, scharr, prewitt\n",
    "from skimage import color\n",
    "from skimage import io\n",
    "\n",
    "img = color.rgb2gray(io.imread(imList[imInd]));\n",
    "\n",
    "edge_sobel = sobel(img)\n",
    "edge_scharr = scharr(img)\n",
    "edge_prewitt = prewitt(img)\n",
    "\n",
    "diff_scharr_prewitt = edge_scharr - edge_prewitt\n",
    "diff_scharr_sobel = edge_scharr - edge_sobel\n",
    "max_diff = np.max(np.maximum(diff_scharr_prewitt, diff_scharr_sobel))\n",
    "\n",
    "fig, ((ax0, ax1), (ax2, ax3)) = plt.subplots(nrows=2, ncols=2, sharex=True, sharey=True, subplot_kw={'adjustable':'box-forced'})\n",
    "\n",
    "ax0.imshow(img, cmap=plt.cm.gray)\n",
    "ax0.set_title('Original image')\n",
    "ax0.axis('off')\n",
    "\n",
    "ax1.imshow(edge_scharr, cmap=plt.cm.gray)\n",
    "ax1.set_title('Scharr Edge Detection')\n",
    "ax1.axis('off')\n",
    "\n",
    "ax2.imshow(diff_scharr_prewitt, cmap=plt.cm.jet, vmax=max_diff)\n",
    "ax2.set_title('Scharr - Prewitt')\n",
    "ax2.axis('off')\n",
    "\n",
    "ax3.imshow(diff_scharr_sobel, cmap=plt.cm.jet, vmax=max_diff)\n",
    "ax3.set_title('Scharr - Sobel')\n",
    "ax3.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
