{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2222\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This is code for extracting NN features of face image data \n",
    "and then fit a linear model to predict social attributes of a face\n",
    "Available dataset: TWIN, CHICAGO and MIT\n",
    "Available NN feature: 'caffeNet','vgg16','vggFace' and 'faceSNN'\n",
    "\n",
    "BY Linjie Li\n",
    "Please run this code on guru2/neon server\n",
    "'''\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "\n",
    "from sklearn.decomposition import PCA as sklearnPCA\n",
    "\n",
    "# Load image dataset#\n",
    "Dataset = 'mit' # 'twin', 'chicago' or 'mit', 'zhihu' or 'funnyFace'\n",
    "if Dataset == 'twin':\n",
    "    imPath = '../../processing/imageProcessing/paddedImages/'\n",
    "    ext = '.png'\n",
    "elif Dataset == 'chicago':\n",
    "    imPath = '../../ChicagoFaceDataset/CFD Version 2.0/CFD 2.0 Images/'\n",
    "    ext = 'N.jpg'\n",
    "elif Dataset == 'mit':\n",
    "    imPath = '../../MIT2kFaceDataset/2kfaces/'\n",
    "    ext = '.jpg'\n",
    "elif Dataset =='funnyFace':\n",
    "    imPath = '../funnyFace/'\n",
    "    ext = '.png'\n",
    "else:\n",
    "    imPath = '../../../zhihu/'\n",
    "    ext = '.jpg'\n",
    "imList = []\n",
    "for dirpath, dirnames, filenames in os.walk(imPath):\n",
    "    for filename in [f for f in filenames if f.endswith(ext)]:\n",
    "        imList.append(os.path.join(dirpath, filename))\n",
    "imList.sort()\n",
    "print len(imList)\n",
    "#print imPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/dist-packages/skimage/io/_plugins/plugin.py:47: DeprecationWarning: You passed a bytestring as `filenames`. This will not work on Python 3. Use `cp.read_file()` or switch to using Unicode strings across the board.\n",
      "  cp.read(f)\n",
      "/usr/lib/python2.7/dist-packages/skimage/io/_plugins/plugin.py:47: DeprecationWarning: You passed a bytestring as `filenames`. This will not work on Python 3. Use `cp.read_file()` or switch to using Unicode strings across the board.\n",
      "  cp.read(f)\n",
      "/usr/lib/python2.7/dist-packages/skimage/io/_plugins/plugin.py:47: DeprecationWarning: You passed a bytestring as `filenames`. This will not work on Python 3. Use `cp.read_file()` or switch to using Unicode strings across the board.\n",
      "  cp.read(f)\n",
      "/usr/lib/python2.7/dist-packages/skimage/io/_plugins/plugin.py:47: DeprecationWarning: You passed a bytestring as `filenames`. This will not work on Python 3. Use `cp.read_file()` or switch to using Unicode strings across the board.\n",
      "  cp.read(f)\n",
      "/usr/lib/python2.7/dist-packages/skimage/io/_plugins/plugin.py:47: DeprecationWarning: You passed a bytestring as `filenames`. This will not work on Python 3. Use `cp.read_file()` or switch to using Unicode strings across the board.\n",
      "  cp.read(f)\n",
      "/usr/lib/python2.7/dist-packages/skimage/io/_plugins/plugin.py:47: DeprecationWarning: You passed a bytestring as `filenames`. This will not work on Python 3. Use `cp.read_file()` or switch to using Unicode strings across the board.\n",
      "  cp.read(f)\n",
      "/usr/lib/python2.7/dist-packages/skimage/io/_plugins/plugin.py:47: DeprecationWarning: You passed a bytestring as `filenames`. This will not work on Python 3. Use `cp.read_file()` or switch to using Unicode strings across the board.\n",
      "  cp.read(f)\n",
      "/usr/lib/python2.7/dist-packages/skimage/io/_plugins/plugin.py:47: DeprecationWarning: You passed a bytestring as `filenames`. This will not work on Python 3. Use `cp.read_file()` or switch to using Unicode strings across the board.\n",
      "  cp.read(f)\n",
      "/usr/lib/python2.7/dist-packages/skimage/io/_plugins/plugin.py:47: DeprecationWarning: You passed a bytestring as `filenames`. This will not work on Python 3. Use `cp.read_file()` or switch to using Unicode strings across the board.\n",
      "  cp.read(f)\n",
      "/usr/lib/python2.7/dist-packages/skimage/io/_plugins/plugin.py:47: DeprecationWarning: You passed a bytestring as `filenames`. This will not work on Python 3. Use `cp.read_file()` or switch to using Unicode strings across the board.\n",
      "  cp.read(f)\n",
      "/usr/lib/python2.7/dist-packages/skimage/io/_plugins/plugin.py:47: DeprecationWarning: You passed a bytestring as `filenames`. This will not work on Python 3. Use `cp.read_file()` or switch to using Unicode strings across the board.\n",
      "  cp.read(f)\n",
      "/usr/lib/python2.7/dist-packages/skimage/io/_plugins/plugin.py:47: DeprecationWarning: You passed a bytestring as `filenames`. This will not work on Python 3. Use `cp.read_file()` or switch to using Unicode strings across the board.\n",
      "  cp.read(f)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean-subtracted values: [('B', 104.0069879317889), ('G', 116.66876761696767), ('R', 122.6789143406786)]\n",
      "Defining the net!\n",
      "conv1_1\t(64, 3, 3, 3) (64,)\n",
      "conv1_2\t(64, 64, 3, 3) (64,)\n",
      "conv2_1\t(128, 64, 3, 3) (128,)\n",
      "conv2_2\t(128, 128, 3, 3) (128,)\n",
      "conv3_1\t(256, 128, 3, 3) (256,)\n",
      "conv3_2\t(256, 256, 3, 3) (256,)\n",
      "conv3_3\t(256, 256, 3, 3) (256,)\n",
      "conv4_1\t(512, 256, 3, 3) (512,)\n",
      "conv4_2\t(512, 512, 3, 3) (512,)\n",
      "conv4_3\t(512, 512, 3, 3) (512,)\n",
      "conv5_1\t(512, 512, 3, 3) (512,)\n",
      "conv5_2\t(512, 512, 3, 3) (512,)\n",
      "conv5_3\t(512, 512, 3, 3) (512,)\n",
      "fc6\t(4096, 25088) (4096,)\n",
      "fc7\t(4096, 4096) (4096,)\n",
      "fc8\t(1000, 4096) (1000,)\n"
     ]
    }
   ],
   "source": [
    "# Make sure that caffe is on the python path:\n",
    "caffe_root = '/home/lli-ms/caffe/'\n",
    "pretrained_model_root = '/home/lli-ms/caffe/'\n",
    "\n",
    "# run this line one time only!\n",
    "import sys\n",
    "caffePython = pretrained_model_root + 'python'\n",
    "if caffePython not in sys.path:\n",
    "    sys.path.insert(0, caffePython)\n",
    "\n",
    "\n",
    "import caffe\n",
    "# Load mean\n",
    "mu = np.load(caffe_root + 'python/caffe/imagenet/ilsvrc_2012_mean.npy')\n",
    "mu = mu.mean(1).mean(1)  # average over pixels to obtain the mean (BGR) pixel values\n",
    "print 'mean-subtracted values:', zip('BGR', mu)\n",
    "\n",
    "# Load the trained net\n",
    "MODEL = 'vgg16' #'caffeNet','vgg16','vggFace' or 'faceSNN'\n",
    "\n",
    "saveFigPath = '../Result/'+Dataset+'/'+MODEL\n",
    "if not os.path.exists(saveFigPath):\n",
    "    os.makedirs(saveFigPath)\n",
    "    \n",
    "if MODEL == 'vgg16':\n",
    "    MODEL_FILE = caffe_root +'models/VGG16/VGG_ILSVRC_16_layers_deploy.prototxt'\n",
    "    PRETRAINED_FILE = caffe_root + 'models/VGG16/VGG_ILSVRC_16_layers.caffemodel'\n",
    "elif MODEL == 'caffeNet':\n",
    "    MODEL_FILE = caffe_root + 'models/bvlc_reference_caffenet/deploy.prototxt'\n",
    "    PRETRAINED_FILE = caffe_root + 'models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel'\n",
    "elif MODEL == 'vggFace':\n",
    "    MODEL_FILE = caffe_root + 'models/VGGFACE/VGG_CNN_F_deploy.prototxt'\n",
    "    PRETRAINED_FILE = caffe_root + 'models/VGGFACE/VGG_CNN_F.caffemodel'\n",
    "    MEAN_FILE = caffe_root + 'models/VGGFACE/VGG_mean.binaryproto'\n",
    "else:\n",
    "    MODEL = 'faceSNN'\n",
    "    MODEL_FILE = caffe_root +'models/sraonet/siamese_lecun_deploy.prototxt'\n",
    "    PRETRAINED_FILE = caffe_root + 'models/sraonet/snapshots/sraonet_lecun_gd_sub2_iter_100000.caffemodel'\n",
    "    \n",
    "caffe.set_device(1)\n",
    "caffe.set_mode_gpu()\n",
    "if not os.path.isfile(PRETRAINED_FILE):\n",
    "    print(\"No caffemodel!!!\")\n",
    "elif not os.path.isfile(MODEL_FILE):\n",
    "    print(\"No MODEL !!!\")\n",
    "else:\n",
    "    print \"Defining the net!\"\n",
    "    net = caffe.Net(MODEL_FILE,\n",
    "                PRETRAINED_FILE,\n",
    "                caffe.TEST)\n",
    "# input preprocessing: 'data' is the name of the input blob == net.inputs[0]\n",
    "transformer = caffe.io.Transformer({'data': net.blobs['data'].data.shape})\n",
    "if MODEL != 'faceSNN':\n",
    "    # subtract the dataset-mean value in each channel\n",
    "    transformer.set_mean('data', mu)\n",
    "for layer_name, param in net.params.iteritems():\n",
    "    print layer_name + '\\t' + str(param[0].data.shape), str(param[1].data.shape)\n",
    "transformer.set_transpose('data', (2,0,1))\n",
    "# the reference model operates on images in [0,255] range instead of [0,1]\n",
    "transformer.set_raw_scale('data', 255) \n",
    "# the reference model has channels in BGR order instead of RGB\n",
    "transformer.set_channel_swap('data', (2,1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100352\n"
     ]
    }
   ],
   "source": [
    "# read in image list \n",
    "def readFile(fName):\n",
    "    text_file = open(fName, \"r\")\n",
    "    lines = text_file.read().split('\\n')\n",
    "    text_file.close()\n",
    "    return lines\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10, 10)\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "if MODEL == 'vgg16' or MODEL == 'vggFace':\n",
    "    imgeReshape = [224,224]\n",
    "    featureLayer = 'conv5_2' \n",
    "elif MODEL == 'caffeNet':\n",
    "    imgeReshape = [227,227]\n",
    "    featureLayer = 'fc6'\n",
    "else:\n",
    "    imgeReshape = [56,46]\n",
    "    featureLayer = 'fc6'\n",
    "if 'fc' in featureLayer:\n",
    "    featureNum = net.params[featureLayer][1].data.shape[0]\n",
    "else:\n",
    "    featureNum = net.blobs[featureLayer].data.flatten().shape[0]/net.blobs[featureLayer].data.shape[0]\n",
    "    \n",
    "if Dataset == 'twin':\n",
    "    features = np.zeros([4,len(imList)/4,featureNum])\n",
    "    perImNum = len(imList)/4\n",
    "    img_type_num = {}\n",
    "    img_type_index = {}\n",
    "    img_type_list = {}\n",
    "    type_index = 0\n",
    "else:\n",
    "    features = np.zeros([len(imList),featureNum])\n",
    "print featureNum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "totalNum = 0\n",
    "\n",
    "# print len(imList)\n",
    "for img in imList:\n",
    "    imgName = os.path.basename(img)\n",
    "    if imgName.endswith(('.jpg','.png')):\n",
    "        input_image = caffe.io.load_image(img)\n",
    "        net.blobs['data'].reshape(1,3,imgeReshape[0],imgeReshape[1])\n",
    "        net.blobs['data'].data[...] = transformer.preprocess('data', input_image)\n",
    "        out = net.forward()\n",
    "        feat = net.blobs[featureLayer].data\n",
    "        if Dataset =='twin':\n",
    "            img_type = int(imgName[7:-4])/perImNum\n",
    "            img_index = int(imgName[7:-4])%perImNum\n",
    "            #print 'img_type:',img_type\n",
    "            if img_type in img_type_num.keys():\n",
    "                img_type_num[img_type] = img_type_num[img_type] + 1\n",
    "                img_type_list[img_type][img_index] = img\n",
    "            else:\n",
    "                img_type_num[img_type] = 0\n",
    "                img_type_list[img_type] = [None]*perImNum\n",
    "                img_type_index[img_type] = type_index\n",
    "                type_index +=1\n",
    "            #print 'img_type_index:',img_type_index[img_type]\n",
    "            features[img_type_index[img_type],img_type_num[img_type]] = feat.flatten()\n",
    "        else:\n",
    "            # need to be further revised!\n",
    "            features[totalNum] = feat.flatten()\n",
    "            #print features[totalNum]\n",
    "        totalNum +=1\n",
    "    else:\n",
    "        print img\n",
    "#print len(img_type_num)\n",
    "print totalNum\n",
    "#print img_type_list\n",
    "\n",
    "if Dataset == 'twin':\n",
    "    featureMat = np.zeros((totalNum,featureNum))\n",
    "    k = 0\n",
    "    for i in range(features.shape[0]):\n",
    "        for j in range(features[i].shape[0]):\n",
    "            if sum(features[i,j,:])!=0:\n",
    "                featureMat[k,:] = features[i,j,:]\n",
    "                k +=1\n",
    "else:\n",
    "    featureMat = features\n",
    "#print featureMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if MODEL != 'faceSNN':\n",
    "    explained_variance = 0.90\n",
    "else:\n",
    "    explained_variance = featureNum\n",
    "\n",
    "sklearn_pca = sklearnPCA(n_components=explained_variance, whiten  = True)\n",
    "feature_transf = sklearn_pca.fit_transform(featureMat)\n",
    "print 'The number of PCs needed to retain %.3f variance is %d.' \\\n",
    "      % (explained_variance, feature_transf.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('/home/lli-ms/features/'+MODEL+'_'+featureLayer+'_'+Dataset+\\\n",
    "           '_feature_pca.csv', feature_transf, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "MODEL = 'vgg16'\n",
    "Dataset = 'mit'\n",
    "featureLayer = 'conv5_2'\n",
    "feature_transf = np.loadtxt('/home/lli-ms/features/'+MODEL+'_'+featureLayer+'_'+\\\n",
    "                            Dataset+'_feature_pca.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "#print sys.path\n",
    "# local\n",
    "# PkgPath = '/Users/Olivialinlin/Documents/Github/attractiveness_datamining/linjieCode/code'\n",
    "# server\n",
    "PkgPath = '/home/lli-ms/attractiveness_datamining/linjieCode/code'\n",
    "\n",
    "if PkgPath not in sys.path:\n",
    "    sys.path.insert(0, PkgPath)\n",
    "#print sys.path\n",
    "from xVal_train_test import Train_Test\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.285714  4.2       5.933333 ...,  3.666667  2.933333  2.266667]\n",
      " [ 3.333333  4.733333  5.866667 ...,  4.333333  3.2       3.666667]\n",
      " [ 2.666667  3.866667  5.933333 ...,  3.6       3.8       3.666667]\n",
      " ..., \n",
      " [ 4.066667  5.        6.066667 ...,  3.        2.666667  3.866667]\n",
      " [ 4.4       5.066667  5.066667 ...,  4.066667  3.066667  5.4     ]\n",
      " [ 3.8       3.533333  5.333333 ...,  4.533333  3.733333  3.8     ]]\n"
     ]
    }
   ],
   "source": [
    "socialMeasures = '../Result/mit/socialMeasures.csv'\n",
    "socialMeasures = pd.read_csv(socialMeasures,index_col = 0)\n",
    "socialAttr = socialMeasures.columns.tolist()\n",
    "delElement = ['subage.1', 'submale.1', 'subrace.1','subage', 'submale',\\\n",
    "              'subrace','catch', 'catchAns','catch.1','catchAns.1']\n",
    "social2Attr = [x for x in socialAttr if x not in delElement]\n",
    "socialMeasuresClean = socialMeasures.loc[:,social2Attr].as_matrix()\n",
    "print socialMeasuresClean\n",
    "np.savetxt('../Result/mit/socialMeasuresClean.csv', socialMeasuresClean, delimiter=',')\n",
    "# print socialMeasures\n",
    "# socialMeasures = pd.read_csv(socialMeasures,index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['trustworthy', 'unattractive', 'unemotional', 'unfamiliar', 'unfriendly', 'unhappy', 'weird', 'aggressive', 'attractive', 'caring', 'emotStable', 'emotional', 'familiar', 'friendly', 'happy', 'humble', 'interesting', 'irresponsible', 'mean', 'memorable', 'normal', 'sociable', 'typical', 'uncertain', 'uncommon', 'unintelligent', 'untrustworthy']\n",
      "trustworthy\n",
      "mean rating:  5.60900627543\n",
      "**************************Result of train and test**************************************\n",
      "number of features: 98\n",
      "On validation set:\n",
      "Residual sum of squares: 0.44\n",
      "Variance score is: 0.50\n",
      "Correlation between predicted ratings and actual ratings is: 0.7091\n",
      " \n",
      "On training set:\n",
      "Residual sum of squares: 0.34\n",
      "Variance score is: 0.61\n",
      "Correlation between predicted ratings and actual ratings is: 0.7845\n",
      "****************************************************************************************\n",
      "unattractive\n",
      "mean rating:  4.26256222862\n",
      "**************************Result of train and test**************************************\n",
      "number of features: 39\n",
      "On validation set:\n",
      "Residual sum of squares: 0.71\n",
      "Variance score is: 0.46\n",
      "Correlation between predicted ratings and actual ratings is: 0.6786\n",
      " \n",
      "On training set:\n",
      "Residual sum of squares: 0.57\n",
      "Variance score is: 0.56\n",
      "Correlation between predicted ratings and actual ratings is: 0.7526\n",
      "****************************************************************************************\n",
      "unemotional\n",
      "mean rating:  3.81256567687\n",
      "**************************Result of train and test**************************************\n",
      "number of features: 147\n",
      "On validation set:\n",
      "Residual sum of squares: 0.43\n",
      "Variance score is: 0.54\n",
      "Correlation between predicted ratings and actual ratings is: 0.7341\n",
      " \n",
      "On training set:\n",
      "Residual sum of squares: 0.36\n",
      "Variance score is: 0.62\n",
      "Correlation between predicted ratings and actual ratings is: 0.7879\n",
      "****************************************************************************************\n",
      "unfamiliar\n",
      "mean rating:  4.4013349892\n",
      "**************************Result of train and test**************************************\n",
      "number of features: 98\n",
      "On validation set:\n",
      "Residual sum of squares: 0.41\n",
      "Variance score is: 0.16\n",
      "Correlation between predicted ratings and actual ratings is: 0.4092\n",
      " \n",
      "On training set:\n",
      "Residual sum of squares: 0.35\n",
      "Variance score is: 0.27\n",
      "Correlation between predicted ratings and actual ratings is: 0.5166\n",
      "****************************************************************************************\n",
      "unfriendly\n",
      "mean rating:  3.62069081908\n",
      "**************************Result of train and test**************************************\n",
      "number of features: 108\n",
      "On validation set:\n",
      "Residual sum of squares: 0.64\n",
      "Variance score is: 0.58\n",
      "Correlation between predicted ratings and actual ratings is: 0.7605\n",
      " \n",
      "On training set:\n",
      "Residual sum of squares: 0.48\n",
      "Variance score is: 0.68\n",
      "Correlation between predicted ratings and actual ratings is: 0.8284\n",
      "****************************************************************************************\n",
      "unhappy\n",
      "mean rating:  3.6158184685\n",
      "**************************Result of train and test**************************************\n",
      "number of features: 313\n",
      "On validation set:\n",
      "Residual sum of squares: 0.66\n",
      "Variance score is: 0.61\n",
      "Correlation between predicted ratings and actual ratings is: 0.7826\n",
      " \n",
      "On training set:\n",
      "Residual sum of squares: 0.49\n",
      "Variance score is: 0.70\n",
      "Correlation between predicted ratings and actual ratings is: 0.8405\n",
      "****************************************************************************************\n",
      "weird\n",
      "mean rating:  3.63755814401\n",
      "**************************Result of train and test**************************************\n",
      "number of features: 137\n",
      "On validation set:\n",
      "Residual sum of squares: 0.67\n",
      "Variance score is: 0.29\n",
      "Correlation between predicted ratings and actual ratings is: 0.5401\n",
      " \n",
      "On training set:\n",
      "Residual sum of squares: 0.56\n",
      "Variance score is: 0.40\n",
      "Correlation between predicted ratings and actual ratings is: 0.6375\n",
      "****************************************************************************************\n",
      "aggressive\n",
      "mean rating:  3.68906388164\n",
      "**************************Result of train and test**************************************\n",
      "number of features: 333\n",
      "On validation set:\n",
      "Residual sum of squares: 0.66\n",
      "Variance score is: 0.48\n",
      "Correlation between predicted ratings and actual ratings is: 0.6973\n",
      " \n",
      "On training set:\n",
      "Residual sum of squares: 0.53\n",
      "Variance score is: 0.59\n",
      "Correlation between predicted ratings and actual ratings is: 0.7669\n",
      "****************************************************************************************\n",
      "attractive\n",
      "mean rating:  4.938305509\n",
      "**************************Result of train and test**************************************\n",
      "number of features: 166\n",
      "On validation set:\n",
      "Residual sum of squares: 0.67\n",
      "Variance score is: 0.54\n",
      "Correlation between predicted ratings and actual ratings is: 0.7332\n",
      " \n",
      "On training set:\n",
      "Residual sum of squares: 0.51\n",
      "Variance score is: 0.65\n",
      "Correlation between predicted ratings and actual ratings is: 0.8055\n",
      "****************************************************************************************\n",
      "caring\n",
      "mean rating:  5.54319240594\n",
      "**************************Result of train and test**************************************\n",
      "number of features: 88\n",
      "On validation set:\n",
      "Residual sum of squares: 0.47\n",
      "Variance score is: 0.59\n",
      "Correlation between predicted ratings and actual ratings is: 0.7665\n",
      " \n",
      "On training set:\n",
      "Residual sum of squares: 0.36\n",
      "Variance score is: 0.68\n",
      "Correlation between predicted ratings and actual ratings is: 0.8259\n",
      "****************************************************************************************\n",
      "emotStable\n",
      "mean rating:  5.72547014446\n",
      "**************************Result of train and test**************************************\n",
      "number of features: 108\n",
      "On validation set:\n",
      "Residual sum of squares: 0.43\n",
      "Variance score is: 0.40\n",
      "Correlation between predicted ratings and actual ratings is: 0.6387\n",
      " \n",
      "On training set:\n",
      "Residual sum of squares: 0.34\n",
      "Variance score is: 0.53\n",
      "Correlation between predicted ratings and actual ratings is: 0.7267\n",
      "****************************************************************************************\n",
      "emotional\n",
      "mean rating:  4.85457467462\n",
      "**************************Result of train and test**************************************\n",
      "number of features: 20\n",
      "On validation set:\n",
      "Residual sum of squares: 0.32\n",
      "Variance score is: 0.35\n",
      "Correlation between predicted ratings and actual ratings is: 0.5948\n",
      " \n",
      "On training set:\n",
      "Residual sum of squares: 0.28\n",
      "Variance score is: 0.44\n",
      "Correlation between predicted ratings and actual ratings is: 0.6607\n",
      "****************************************************************************************\n",
      "familiar\n",
      "mean rating:  4.82254823987\n",
      "**************************Result of train and test**************************************\n",
      "number of features: 29\n",
      "On validation set:\n",
      "Residual sum of squares: 0.39\n",
      "Variance score is: 0.15\n",
      "Correlation between predicted ratings and actual ratings is: 0.4146\n",
      " \n",
      "On training set:\n",
      "Residual sum of squares: 0.33\n",
      "Variance score is: 0.28\n",
      "Correlation between predicted ratings and actual ratings is: 0.5240\n",
      "****************************************************************************************\n",
      "friendly\n",
      "mean rating:  5.82059405266\n",
      "**************************Result of train and test**************************************\n",
      "number of features: 127\n",
      "On validation set:\n",
      "Residual sum of squares: 0.56\n",
      "Variance score is: 0.63\n",
      "Correlation between predicted ratings and actual ratings is: 0.7955\n",
      " \n",
      "On training set:\n",
      "Residual sum of squares: 0.42\n",
      "Variance score is: 0.72\n",
      "Correlation between predicted ratings and actual ratings is: 0.8525\n",
      "****************************************************************************************\n",
      "happy\n",
      "mean rating:  5.76331922367\n",
      "**************************Result of train and test**************************************\n",
      "number of features: 39\n",
      "On validation set:\n",
      "Residual sum of squares: 0.61\n",
      "Variance score is: 0.68\n",
      "Correlation between predicted ratings and actual ratings is: 0.8239\n",
      " \n",
      "On training set:\n",
      "Residual sum of squares: 0.48\n",
      "Variance score is: 0.75\n",
      "Correlation between predicted ratings and actual ratings is: 0.8678\n",
      "****************************************************************************************\n",
      "humble\n",
      "mean rating:  5.25931088254\n",
      "**************************Result of train and test**************************************\n",
      "number of features: 137\n",
      "On validation set:\n",
      "Residual sum of squares: 0.49\n",
      "Variance score is: 0.35\n",
      "Correlation between predicted ratings and actual ratings is: 0.5940\n",
      " \n",
      "On training set:\n",
      "Residual sum of squares: 0.41\n",
      "Variance score is: 0.47\n",
      "Correlation between predicted ratings and actual ratings is: 0.6872\n",
      "****************************************************************************************\n",
      "interesting\n",
      "mean rating:  5.1925439811\n",
      "**************************Result of train and test**************************************\n",
      "number of features: 88\n",
      "On validation set:\n",
      "Residual sum of squares: 0.38\n",
      "Variance score is: 0.31\n",
      "Correlation between predicted ratings and actual ratings is: 0.5659\n",
      " \n",
      "On training set:\n",
      "Residual sum of squares: 0.31\n",
      "Variance score is: 0.44\n",
      "Correlation between predicted ratings and actual ratings is: 0.6615\n",
      "****************************************************************************************\n",
      "irresponsible\n",
      "mean rating:  3.49412266427\n",
      "**************************Result of train and test**************************************\n",
      "number of features: 108\n",
      "On validation set:\n",
      "Residual sum of squares: 0.48\n",
      "Variance score is: 0.42\n",
      "Correlation between predicted ratings and actual ratings is: 0.6505\n",
      " \n",
      "On training set:\n",
      "Residual sum of squares: 0.39\n",
      "Variance score is: 0.53\n",
      "Correlation between predicted ratings and actual ratings is: 0.7265\n",
      "****************************************************************************************\n",
      "mean\n",
      "mean rating:  3.50907456256\n",
      "**************************Result of train and test**************************************\n",
      "number of features: 108\n",
      "On validation set:\n",
      "Residual sum of squares: 0.66\n",
      "Variance score is: 0.51\n",
      "Correlation between predicted ratings and actual ratings is: 0.7141\n",
      " \n",
      "On training set:\n",
      "Residual sum of squares: 0.50\n",
      "Variance score is: 0.62\n",
      "Correlation between predicted ratings and actual ratings is: 0.7905\n",
      "****************************************************************************************\n",
      "memorable\n",
      "mean rating:  4.96662179163\n",
      "**************************Result of train and test**************************************\n",
      "number of features: 78\n",
      "On validation set:\n",
      "Residual sum of squares: 0.38\n",
      "Variance score is: 0.20\n",
      "Correlation between predicted ratings and actual ratings is: 0.4609\n",
      " \n",
      "On training set:\n",
      "Residual sum of squares: 0.32\n",
      "Variance score is: 0.32\n",
      "Correlation between predicted ratings and actual ratings is: 0.5664\n",
      "****************************************************************************************\n",
      "normal\n",
      "mean rating:  6.0043479721\n",
      "**************************Result of train and test**************************************\n",
      "number of features: 49\n",
      "On validation set:\n",
      "Residual sum of squares: 0.43\n",
      "Variance score is: 0.34\n",
      "Correlation between predicted ratings and actual ratings is: 0.5872\n",
      " \n",
      "On training set:\n",
      "Residual sum of squares: 0.36\n",
      "Variance score is: 0.45\n",
      "Correlation between predicted ratings and actual ratings is: 0.6708\n",
      "****************************************************************************************\n",
      "sociable\n",
      "mean rating:  5.81801230153\n",
      "**************************Result of train and test**************************************\n",
      "number of features: 186\n",
      "On validation set:\n",
      "Residual sum of squares: 0.52\n",
      "Variance score is: 0.58\n",
      "Correlation between predicted ratings and actual ratings is: 0.7609\n",
      " \n",
      "On training set:\n",
      "Residual sum of squares: 0.41\n",
      "Variance score is: 0.67\n",
      "Correlation between predicted ratings and actual ratings is: 0.8173\n",
      "****************************************************************************************\n",
      "typical\n",
      "mean rating:  5.28849724392\n",
      "**************************Result of train and test**************************************\n",
      "number of features: 206\n",
      "On validation set:\n",
      "Residual sum of squares: 0.37\n",
      "Variance score is: 0.17\n",
      "Correlation between predicted ratings and actual ratings is: 0.4163\n",
      " \n",
      "On training set:\n",
      "Residual sum of squares: 0.33\n",
      "Variance score is: 0.26\n",
      "Correlation between predicted ratings and actual ratings is: 0.5098\n",
      "****************************************************************************************\n",
      "uncertain\n",
      "mean rating:  3.71894901845\n",
      "**************************Result of train and test**************************************\n",
      "number of features: 98\n",
      "On validation set:\n",
      "Residual sum of squares: 0.42\n",
      "Variance score is: 0.37\n",
      "Correlation between predicted ratings and actual ratings is: 0.6121\n",
      " \n",
      "On training set:\n",
      "Residual sum of squares: 0.37\n",
      "Variance score is: 0.46\n",
      "Correlation between predicted ratings and actual ratings is: 0.6769\n",
      "****************************************************************************************\n",
      "uncommon\n",
      "mean rating:  3.8759900027\n",
      "**************************Result of train and test**************************************\n",
      "number of features: 20\n",
      "On validation set:\n",
      "Residual sum of squares: 0.40\n",
      "Variance score is: 0.11\n",
      "Correlation between predicted ratings and actual ratings is: 0.3708\n",
      " \n",
      "On training set:\n",
      "Residual sum of squares: 0.32\n",
      "Variance score is: 0.27\n",
      "Correlation between predicted ratings and actual ratings is: 0.5130\n",
      "****************************************************************************************\n",
      "unintelligent\n",
      "mean rating:  3.41764200135\n",
      "**************************Result of train and test**************************************\n",
      "number of features: 166\n",
      "On validation set:\n",
      "Residual sum of squares: 0.43\n",
      "Variance score is: 0.29\n",
      "Correlation between predicted ratings and actual ratings is: 0.5481\n",
      " \n",
      "On training set:\n",
      "Residual sum of squares: 0.33\n",
      "Variance score is: 0.45\n",
      "Correlation between predicted ratings and actual ratings is: 0.6709\n",
      "****************************************************************************************\n",
      "untrustworthy\n",
      "mean rating:  3.65333764671\n",
      "**************************Result of train and test**************************************\n",
      "number of features: 98\n",
      "On validation set:\n",
      "Residual sum of squares: 0.56\n",
      "Variance score is: 0.46\n",
      "Correlation between predicted ratings and actual ratings is: 0.6798\n",
      " \n",
      "On training set:\n",
      "Residual sum of squares: 0.44\n",
      "Variance score is: 0.57\n",
      "Correlation between predicted ratings and actual ratings is: 0.7583\n",
      "****************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "print social2Attr[13:]\n",
    "for attr in social2Attr[13:]:\n",
    "    print attr\n",
    "    mean_rating = socialMeasures.loc[:,attr].tolist()\n",
    "    mean_rating = map(float, mean_rating)\n",
    "    mean_rating = np.array(mean_rating)\n",
    "    baseLine = mean_rating.mean()\n",
    "    print 'mean rating: ', baseLine\n",
    "\n",
    "    predictionModel = sklearn.linear_model.RidgeCV(alphas=np.logspace(-3,2,num=20), fit_intercept=True)\n",
    "    Train_Test(mean_rating, feature_transf,xVal = True,\\\n",
    "                                            pModel = predictionModel,getMaxMin = False,\\\n",
    "                                           numTrain = 50,savePath = '../Result/'+Dataset,\\\n",
    "                                             MODEL= MODEL, plotPredActual = False,returnModel = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratingPath = '../Result/'+Dataset+'/meanRating.csv'\n",
    "mean_rating = pd.read_csv(ratingPath,index_col = 0).as_matrix()[:,0].tolist()\n",
    "mean_rating = map(float, mean_rating)\n",
    "mean_rating = np.array(mean_rating)\n",
    "\n",
    "baseLine = mean_rating.mean()\n",
    "print 'mean rating: ', baseLine\n",
    "\n",
    "predictionModel = sklearn.linear_model.RidgeCV(alphas=np.logspace(-3,2,num=20), fit_intercept=True)\n",
    "myModel \\\n",
    "         = Train_Test(mean_rating, feature_transf,xVal = True,\\\n",
    "                                        pModel = predictionModel,getMaxMin = False,\\\n",
    "                                       numTrain = 50,savePath = '../Result/'+Dataset,\\\n",
    "                                         MODEL= MODEL, plotPredActual = False,returnModel = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
