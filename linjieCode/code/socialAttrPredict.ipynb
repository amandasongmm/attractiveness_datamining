{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2222\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This is code for extracting NN features of face image data \n",
    "and then fit a linear model to predict social attributes of a face\n",
    "Available dataset: TWIN, CHICAGO and MIT\n",
    "Available NN feature: 'caffeNet','vgg16','vggFace' and 'faceSNN'\n",
    "\n",
    "BY Linjie Li\n",
    "Please run this code on guru2/neon server\n",
    "'''\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "\n",
    "from sklearn.decomposition import PCA as sklearnPCA\n",
    "\n",
    "# Load image dataset#\n",
    "Dataset = 'mit' # 'twin', 'chicago' or 'mit', 'zhihu' or 'funnyFace'\n",
    "if Dataset == 'twin':\n",
    "    imPath = '../../processing/imageProcessing/paddedImages/'\n",
    "    ext = '.png'\n",
    "elif Dataset == 'chicago':\n",
    "    imPath = '../../ChicagoFaceDataset/CFD Version 2.0/CFD 2.0 Images/'\n",
    "    ext = 'N.jpg'\n",
    "elif Dataset == 'mit':\n",
    "    imPath = '../../MIT2kFaceDataset/2kfaces/'\n",
    "    ext = '.jpg'\n",
    "elif Dataset =='funnyFace':\n",
    "    imPath = '../funnyFace/'\n",
    "    ext = '.png'\n",
    "else:\n",
    "    imPath = '../../../zhihu/'\n",
    "    ext = '.jpg'\n",
    "imList = []\n",
    "for dirpath, dirnames, filenames in os.walk(imPath):\n",
    "    for filename in [f for f in filenames if f.endswith(ext)]:\n",
    "        imList.append(os.path.join(dirpath, filename))\n",
    "imList.sort()\n",
    "print len(imList)\n",
    "#print imPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean-subtracted values: [('B', 104.0069879317889), ('G', 116.66876761696767), ('R', 122.6789143406786)]\n",
      "Defining the net!\n",
      "conv1_1\t(64, 3, 3, 3) (64,)\n",
      "conv1_2\t(64, 64, 3, 3) (64,)\n",
      "conv2_1\t(128, 64, 3, 3) (128,)\n",
      "conv2_2\t(128, 128, 3, 3) (128,)\n",
      "conv3_1\t(256, 128, 3, 3) (256,)\n",
      "conv3_2\t(256, 256, 3, 3) (256,)\n",
      "conv3_3\t(256, 256, 3, 3) (256,)\n",
      "conv4_1\t(512, 256, 3, 3) (512,)\n",
      "conv4_2\t(512, 512, 3, 3) (512,)\n",
      "conv4_3\t(512, 512, 3, 3) (512,)\n",
      "conv5_1\t(512, 512, 3, 3) (512,)\n",
      "conv5_2\t(512, 512, 3, 3) (512,)\n",
      "conv5_3\t(512, 512, 3, 3) (512,)\n",
      "fc6\t(4096, 25088) (4096,)\n",
      "fc7\t(4096, 4096) (4096,)\n",
      "fc8\t(1000, 4096) (1000,)\n"
     ]
    }
   ],
   "source": [
    "# Make sure that caffe is on the python path:\n",
    "#homePath = '/raid/linjieli/'\n",
    "homePath = '/home/lli-ms/'\n",
    "caffe_root = homePath+'caffe/'\n",
    "pretrained_model_root = homePath+'caffe/'\n",
    "\n",
    "# run this line one time only!\n",
    "import sys\n",
    "caffePython = pretrained_model_root + 'python'\n",
    "if caffePython not in sys.path:\n",
    "    sys.path.insert(0, caffePython)\n",
    "\n",
    "\n",
    "import caffe\n",
    "# Load mean\n",
    "mu = np.load(caffe_root + 'python/caffe/imagenet/ilsvrc_2012_mean.npy')\n",
    "mu = mu.mean(1).mean(1)  # average over pixels to obtain the mean (BGR) pixel values\n",
    "print 'mean-subtracted values:', zip('BGR', mu)\n",
    "\n",
    "# Load the trained net\n",
    "MODEL = 'vgg16' #'caffeNet','vgg16','vggFace' or 'faceSNN'\n",
    "\n",
    "saveFigPath = '../Result/'+Dataset+'/'+MODEL\n",
    "if not os.path.exists(saveFigPath):\n",
    "    os.makedirs(saveFigPath)\n",
    "    \n",
    "if MODEL == 'vgg16':\n",
    "    MODEL_FILE = caffe_root +'models/VGG16/VGG_ILSVRC_16_layers_deploy.prototxt'\n",
    "    PRETRAINED_FILE = caffe_root + 'models/VGG16/VGG_ILSVRC_16_layers.caffemodel'\n",
    "elif MODEL == 'caffeNet':\n",
    "    MODEL_FILE = caffe_root + 'models/bvlc_reference_caffenet/deploy.prototxt'\n",
    "    PRETRAINED_FILE = caffe_root + 'models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel'\n",
    "elif MODEL == 'vggFace':\n",
    "    MODEL_FILE = caffe_root + 'models/VGGFACE/VGG_CNN_F_deploy.prototxt'\n",
    "    PRETRAINED_FILE = caffe_root + 'models/VGGFACE/VGG_CNN_F.caffemodel'\n",
    "    MEAN_FILE = caffe_root + 'models/VGGFACE/VGG_mean.binaryproto'\n",
    "else:\n",
    "    MODEL = 'faceSNN'\n",
    "    MODEL_FILE = caffe_root +'models/sraonet/siamese_lecun_deploy.prototxt'\n",
    "    PRETRAINED_FILE = caffe_root + 'models/sraonet/snapshots/sraonet_lecun_gd_sub2_iter_100000.caffemodel'\n",
    "    \n",
    "caffe.set_device(1)\n",
    "caffe.set_mode_gpu()\n",
    "if not os.path.isfile(PRETRAINED_FILE):\n",
    "    print(\"No caffemodel!!!\")\n",
    "elif not os.path.isfile(MODEL_FILE):\n",
    "    print(\"No MODEL !!!\")\n",
    "else:\n",
    "    print \"Defining the net!\"\n",
    "    net = caffe.Net(MODEL_FILE,\n",
    "                PRETRAINED_FILE,\n",
    "                caffe.TEST)\n",
    "# input preprocessing: 'data' is the name of the input blob == net.inputs[0]\n",
    "transformer = caffe.io.Transformer({'data': net.blobs['data'].data.shape})\n",
    "if MODEL != 'faceSNN':\n",
    "    # subtract the dataset-mean value in each channel\n",
    "    transformer.set_mean('data', mu)\n",
    "for layer_name, param in net.params.iteritems():\n",
    "    print layer_name + '\\t' + str(param[0].data.shape), str(param[1].data.shape)\n",
    "transformer.set_transpose('data', (2,0,1))\n",
    "# the reference model operates on images in [0,255] range instead of [0,1]\n",
    "transformer.set_raw_scale('data', 255) \n",
    "# the reference model has channels in BGR order instead of RGB\n",
    "transformer.set_channel_swap('data', (2,1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100352\n"
     ]
    }
   ],
   "source": [
    "# read in image list \n",
    "def readFile(fName):\n",
    "    text_file = open(fName, \"r\")\n",
    "    lines = text_file.read().split('\\n')\n",
    "    text_file.close()\n",
    "    return lines\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10, 10)\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "if MODEL == 'vgg16' or MODEL == 'vggFace':\n",
    "    imgeReshape = [224,224]\n",
    "    featureLayer = 'conv5_2' \n",
    "elif MODEL == 'caffeNet':\n",
    "    imgeReshape = [227,227]\n",
    "    featureLayer = 'fc6'\n",
    "else:\n",
    "    imgeReshape = [56,46]\n",
    "    featureLayer = 'fc6'\n",
    "if 'fc' in featureLayer:\n",
    "    featureNum = net.params[featureLayer][1].data.shape[0]\n",
    "else:\n",
    "    featureNum = net.blobs[featureLayer].data.flatten().shape[0]/net.blobs[featureLayer].data.shape[0]\n",
    "    \n",
    "if Dataset == 'twin':\n",
    "    features = np.zeros([4,len(imList)/4,featureNum])\n",
    "    perImNum = len(imList)/4\n",
    "    img_type_num = {}\n",
    "    img_type_index = {}\n",
    "    img_type_list = {}\n",
    "    type_index = 0\n",
    "else:\n",
    "    features = np.zeros([len(imList),featureNum])\n",
    "print featureNum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2222\n"
     ]
    }
   ],
   "source": [
    "totalNum = 0\n",
    "\n",
    "# print len(imList)\n",
    "for img in imList:\n",
    "    imgName = os.path.basename(img)\n",
    "    if imgName.endswith(('.jpg','.png')):\n",
    "        input_image = caffe.io.load_image(img)\n",
    "        net.blobs['data'].reshape(1,3,imgeReshape[0],imgeReshape[1])\n",
    "        net.blobs['data'].data[...] = transformer.preprocess('data', input_image)\n",
    "        out = net.forward()\n",
    "        feat = net.blobs[featureLayer].data\n",
    "        if Dataset =='twin':\n",
    "            img_type = int(imgName[7:-4])/perImNum\n",
    "            img_index = int(imgName[7:-4])%perImNum\n",
    "            #print 'img_type:',img_type\n",
    "            if img_type in img_type_num.keys():\n",
    "                img_type_num[img_type] = img_type_num[img_type] + 1\n",
    "                img_type_list[img_type][img_index] = img\n",
    "            else:\n",
    "                img_type_num[img_type] = 0\n",
    "                img_type_list[img_type] = [None]*perImNum\n",
    "                img_type_index[img_type] = type_index\n",
    "                type_index +=1\n",
    "            #print 'img_type_index:',img_type_index[img_type]\n",
    "            features[img_type_index[img_type],img_type_num[img_type]] = feat.flatten()\n",
    "        else:\n",
    "            # need to be further revised!\n",
    "            features[totalNum] = feat.flatten()\n",
    "            #print features[totalNum]\n",
    "        totalNum +=1\n",
    "    else:\n",
    "        print img\n",
    "#print len(img_type_num)\n",
    "print totalNum\n",
    "#print img_type_list\n",
    "\n",
    "\n",
    "#print featureMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2221\n",
      "(355, 100352) (1423, 100352) (444, 100352)\n"
     ]
    }
   ],
   "source": [
    "if Dataset == 'twin':\n",
    "    featureMat = np.zeros((totalNum,featureNum))\n",
    "    k = 0\n",
    "    for i in range(features.shape[0]):\n",
    "        for j in range(features[i].shape[0]):\n",
    "            if sum(features[i,j,:])!=0:\n",
    "                featureMat[k,:] = features[i,j,:]\n",
    "                k +=1\n",
    "else:\n",
    "    featureMat = features\n",
    "#split train test validation\n",
    "import random\n",
    "randomInd = range(featureMat.shape[0])\n",
    "random.shuffle(randomInd)\n",
    "print max(randomInd)\n",
    "featureMat = featureMat[randomInd,:]\n",
    "nSamples = featureMat.shape[0]\n",
    "testRatio = 0.2\n",
    "valiRatio = 0.2\n",
    "testFeatures = featureMat[:int(nSamples*testRatio),:]\n",
    "trainFeatures = featureMat[int(nSamples*testRatio):,:]\n",
    "valiFeatures = featureMat[-int(trainFeatures.shape[0]*valiRatio):,:]\n",
    "trainFeatures = trainFeatures[:-int(trainFeatures.shape[0]*valiRatio),:]\n",
    "print valiFeatures.shape, trainFeatures.shape, testFeatures.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(444,) (1778,)\n"
     ]
    }
   ],
   "source": [
    "radomImlist = np.asarray(imList)[randomInd]\n",
    "testIm = radomImlist[:int(nSamples*testRatio)]\n",
    "trainIm = radomImlist[int(nSamples*testRatio):]\n",
    "print testIm.shape, trainIm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of PCs needed to retain 0.950 variance is 858.\n"
     ]
    }
   ],
   "source": [
    "if MODEL != 'faceSNN':\n",
    "    explained_variance = 0.95\n",
    "else:\n",
    "    explained_variance = featureNum\n",
    "\n",
    "sklearn_pca = sklearnPCA(n_components=explained_variance, whiten  = True)\n",
    "trainfeature_transf = sklearn_pca.fit_transform(trainFeatures)\n",
    "print 'The number of PCs needed to retain %.3f variance is %d.' \\\n",
    "      % (explained_variance, trainfeature_transf.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(858, 100352)\n",
      "(1423, 858)\n",
      "(444, 858)\n"
     ]
    }
   ],
   "source": [
    "print sklearn_pca.components_.shape\n",
    "print trainfeature_transf.shape\n",
    "testfeature_tansf = sklearn_pca.transform(testFeatures)\n",
    "print testfeature_tansf.shape\n",
    "valifeature_transf = sklearn_pca.transform(valiFeatures)\n",
    "#component_std = np.std(sklearn_pca.components_,axis = 0,dtype=np.float32)\n",
    "# import scipy\n",
    "# u,s,v = scipy.sparse.linalg.svds(featureMat, k =sklearn_pca.components_.shape[0], which = 'LM')\n",
    "np.savetxt(homePath+'/features/'+MODEL+'_'+featureLayer+'_'+Dataset+\\\n",
    "           'other_trainFeatures.csv', trainfeature_transf, delimiter=',')\n",
    "np.savetxt(homePath+'/features/'+MODEL+'_'+featureLayer+'_'+Dataset+\\\n",
    "           'other_testFeatures.csv', testfeature_tansf, delimiter=',')\n",
    "np.savetxt(homePath+'/features/'+MODEL+'_'+featureLayer+'_'+Dataset+\\\n",
    "           'other_valiFeatures.csv', valifeature_transf, delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.000610992989333\n",
      "(100352,)\n",
      "0.191141622138 -0.622921687518\n",
      "1874.27453938\n",
      "-0.622921687518\n"
     ]
    }
   ],
   "source": [
    "whiten_component = sklearn_pca.components_\n",
    "import math\n",
    "std = [math.sqrt(x) for x in sklearn_pca.explained_variance_]\n",
    "whiten_component_std =np.asarray([ whiten_component[i,:]/std[i] for i in range(len(std))])\n",
    "print np.linalg.norm(whiten_component[1,:]),np.linalg.norm(whiten_component_std[1,:])\n",
    "#print whiten_component \n",
    "print sklearn_pca.mean_.shape\n",
    "#trainFeatures_mean = trainFeatures- np.matlib.repmat(sklearn_pca.mean_, trainFeatures.shape[0], 1)\n",
    "newMat = testFeatures.dot(whiten_component_std.T)\n",
    "print newMat[0,1], testfeature_tansf[0,1]\n",
    "print std[0]\n",
    "#bias = -1*np.mean(newMat,axis = 0)\n",
    "# print bias\n",
    "newNewMat = newMat + bias\n",
    "print newNewMat[0,1]\n",
    "np.savetxt(homePath+'/features/'+MODEL+'_'+featureLayer+'_'+Dataset+\\\n",
    "           'other_weights.csv', whiten_component_std, delimiter=',')\n",
    "np.savetxt(homePath+'/features/'+MODEL+'_'+featureLayer+'_'+Dataset+\\\n",
    "           'other_biases.csv', bias, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  5.45023771e-07   1.44910250e-07  -9.10823708e-21 ...,   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00]\n",
      "-4.40039768957\n"
     ]
    }
   ],
   "source": [
    "print whiten_component_std[0,:]\n",
    "print bias[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1423,) (444,) (355,)\n",
      "../../MIT2kFaceDataset/2kfaces/Google_1_Ralph Rowlett_9_oval.jpg 6.25\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "socialMeasures = '../Result/mit/socialMeasures.csv'\n",
    "socialMeasures = pd.read_csv(socialMeasures,index_col = 0)\n",
    "socialAttr = socialMeasures.columns.tolist()\n",
    "delElement = ['subage.1', 'submale.1', 'subrace.1','subage', 'submale',\\\n",
    "              'subrace','catch', 'catchAns','catch.1','catchAns.1']\n",
    "social2Attr = [x for x in socialAttr if x not in delElement]\n",
    "socialMeasuresClean = socialMeasures.loc[:,social2Attr].as_matrix()\n",
    "#print socialMeasuresClean\n",
    "np.savetxt('../Result/mit/socialMeasuresClean.csv', socialMeasuresClean, delimiter=',')\n",
    "def writeFile(imList, rating,fName):\n",
    "    text_file = open(fName, \"w\")\n",
    "    for i in range(imList.shape[0]):\n",
    "        d = homePath+'attractiveness_datamining/'+imList[i][6:]+' '+str(rating[i])+'\\n'\n",
    "        text_file.write(d)\n",
    "    text_file.close()\n",
    "attr= social2Attr[9]\n",
    "mean_rating = socialMeasures.loc[:,attr].tolist()\n",
    "mean_rating = map(float, mean_rating)\n",
    "mean_rating = np.array(mean_rating)\n",
    "radomRating = mean_rating[randomInd]\n",
    "testRating = radomRating[:int(nSamples*testRatio)]\n",
    "trainRating = radomRating[int(nSamples*testRatio):]\n",
    "valiRating = radomRating[-int(trainRating.shape[0]*valiRatio):]\n",
    "trainSubRating = trainRating[:-int(trainRating.shape[0]*valiRatio)]\n",
    "#writeFile(trainIm,trainRating,'../list/'+attr+'_train.txt')\n",
    "#writeFile(testIm,testRating,'../list/'+attr+'_test.txt')\n",
    "writeFile(trainIm,trainRating,'../data_list/'+attr+'_train.txt')\n",
    "writeFile(testIm,testRating,'../data_list/'+attr+'_test.txt')\n",
    "print trainSubRating.shape,testRating.shape,valiRating.shape\n",
    "# print radomImlist[10],radomRating[10]\n",
    "print imList[randomInd[10]],mean_rating[randomInd[10]]\n",
    "# print socialMeasures\n",
    "# socialMeasures = pd.read_csv(socialMeasures,index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fName = '../Result/Config_vs_VGG16/combined_result.csv'\n",
    "hyP = pd.read_csv(fName,index_col = 0)\n",
    "hyP = hyP.as_matrix()[:,-1].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atypical\n",
      "mean rating:  4.08832261206\n",
      "101\n",
      "**************************Result of train and test**************************************\n",
      "number of features: 101\n",
      "On test set:\n",
      "Residual sum of squares: 0.38\n",
      "Variance score is: 0.15\n",
      "Correlation between predicted ratings and actual ratings is: 0.4177\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.4032\n",
      " \n",
      "On training set:\n",
      "Residual sum of squares: 0.34\n",
      "Variance score is: 0.29\n",
      "Correlation between predicted ratings and actual ratings is: 0.5414\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.5239\n",
      "****************************************************************************************\n",
      "boring\n",
      "mean rating:  4.29054390414\n",
      "161\n",
      "**************************Result of train and test**************************************\n",
      "number of features: 161\n",
      "On test set:\n",
      "Residual sum of squares: 0.44\n",
      "Variance score is: 0.36\n",
      "Correlation between predicted ratings and actual ratings is: 0.6055\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.6116\n",
      " \n",
      "On training set:\n",
      "Residual sum of squares: 0.34\n",
      "Variance score is: 0.50\n",
      "Correlation between predicted ratings and actual ratings is: 0.7058\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.6981\n",
      "****************************************************************************************\n",
      "calm\n",
      "mean rating:  5.8071950108\n",
      "226\n",
      "**************************Result of train and test**************************************\n",
      "number of features: 226\n",
      "On test set:\n",
      "Residual sum of squares: 0.38\n",
      "Variance score is: 0.21\n",
      "Correlation between predicted ratings and actual ratings is: 0.4682\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.3952\n",
      " \n",
      "On training set:\n",
      "Residual sum of squares: 0.30\n",
      "Variance score is: 0.42\n",
      "Correlation between predicted ratings and actual ratings is: 0.6472\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.5765\n",
      "****************************************************************************************\n",
      "cold\n",
      "mean rating:  3.72213710261\n",
      "278\n",
      "**************************Result of train and test**************************************\n",
      "number of features: 278\n",
      "On test set:\n",
      "Residual sum of squares: 0.64\n",
      "Variance score is: 0.58\n",
      "Correlation between predicted ratings and actual ratings is: 0.7607\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.7348\n",
      " \n",
      "On training set:\n",
      "Residual sum of squares: 0.41\n",
      "Variance score is: 0.74\n",
      "Correlation between predicted ratings and actual ratings is: 0.8627\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.8279\n",
      "****************************************************************************************\n",
      "common\n",
      "mean rating:  5.32322733483\n",
      "99\n",
      "**************************Result of train and test**************************************\n",
      "number of features: 99\n",
      "On test set:\n",
      "Residual sum of squares: 0.33\n",
      "Variance score is: 0.13\n",
      "Correlation between predicted ratings and actual ratings is: 0.3840\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.3514\n",
      " \n",
      "On training set:\n",
      "Residual sum of squares: 0.30\n",
      "Variance score is: 0.27\n",
      "Correlation between predicted ratings and actual ratings is: 0.5240\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.5073\n",
      "****************************************************************************************\n",
      "confident\n",
      "mean rating:  5.92087190774\n",
      "175\n",
      "**************************Result of train and test**************************************\n",
      "number of features: 175\n",
      "On test set:\n",
      "Residual sum of squares: 0.40\n",
      "Variance score is: 0.39\n",
      "Correlation between predicted ratings and actual ratings is: 0.6265\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.5866\n",
      " \n",
      "On training set:\n",
      "Residual sum of squares: 0.35\n",
      "Variance score is: 0.49\n",
      "Correlation between predicted ratings and actual ratings is: 0.7004\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.6680\n",
      "****************************************************************************************\n",
      "egotistic\n",
      "mean rating:  4.07612411386\n",
      "266\n",
      "**************************Result of train and test**************************************\n",
      "number of features: 266\n",
      "On test set:\n",
      "Residual sum of squares: 0.57\n",
      "Variance score is: 0.33\n",
      "Correlation between predicted ratings and actual ratings is: 0.5824\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.5745\n",
      " \n",
      "On training set:\n",
      "Residual sum of squares: 0.40\n",
      "Variance score is: 0.57\n",
      "Correlation between predicted ratings and actual ratings is: 0.7564\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.7578\n",
      "****************************************************************************************\n",
      "emotUnstable\n",
      "mean rating:  3.63740073942\n",
      "189\n",
      "**************************Result of train and test**************************************\n",
      "number of features: 189\n",
      "On test set:\n",
      "Residual sum of squares: 0.51\n",
      "Variance score is: 0.40\n",
      "Correlation between predicted ratings and actual ratings is: 0.6352\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.5592\n",
      " \n",
      "On training set:\n",
      "Residual sum of squares: 0.39\n",
      "Variance score is: 0.54\n",
      "Correlation between predicted ratings and actual ratings is: 0.7365\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.6682\n",
      "****************************************************************************************\n",
      "forgettable\n",
      "mean rating:  4.54515863681\n",
      "169\n",
      "**************************Result of train and test**************************************\n",
      "number of features: 169\n",
      "On test set:\n",
      "Residual sum of squares: 0.41\n",
      "Variance score is: 0.21\n",
      "Correlation between predicted ratings and actual ratings is: 0.4643\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.4374\n",
      " \n",
      "On training set:\n",
      "Residual sum of squares: 0.32\n",
      "Variance score is: 0.38\n",
      "Correlation between predicted ratings and actual ratings is: 0.6159\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.5974\n",
      "****************************************************************************************\n",
      "intelligent\n",
      "mean rating:  5.83601266427\n",
      "261\n",
      "**************************Result of train and test**************************************\n",
      "number of features: 261\n",
      "On test set:\n",
      "Residual sum of squares: 0.37\n",
      "Variance score is: 0.34\n",
      "Correlation between predicted ratings and actual ratings is: 0.5869\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.5456\n",
      " \n",
      "On training set:\n",
      "Residual sum of squares: 0.24\n",
      "Variance score is: 0.56\n",
      "Correlation between predicted ratings and actual ratings is: 0.7511\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.6816\n",
      "****************************************************************************************\n",
      "introverted\n",
      "mean rating:  3.93128084518\n",
      "161\n",
      "**************************Result of train and test**************************************\n",
      "number of features: 161\n",
      "On test set:\n",
      "Residual sum of squares: 0.54\n",
      "Variance score is: 0.43\n",
      "Correlation between predicted ratings and actual ratings is: 0.6571\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.6469\n",
      " \n",
      "On training set:\n",
      "Residual sum of squares: 0.39\n",
      "Variance score is: 0.55\n",
      "Correlation between predicted ratings and actual ratings is: 0.7408\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.7334\n",
      "****************************************************************************************\n",
      "kind\n",
      "mean rating:  5.67654606841\n",
      "321\n",
      "**************************Result of train and test**************************************\n",
      "number of features: 321\n",
      "On test set:\n",
      "Residual sum of squares: 0.47\n",
      "Variance score is: 0.59\n",
      "Correlation between predicted ratings and actual ratings is: 0.7686\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.7394\n",
      " \n",
      "On training set:\n",
      "Residual sum of squares: 0.30\n",
      "Variance score is: 0.74\n",
      "Correlation between predicted ratings and actual ratings is: 0.8648\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.8246\n",
      "****************************************************************************************\n",
      "responsible\n",
      "mean rating:  5.86075791584\n",
      "216\n",
      "**************************Result of train and test**************************************\n",
      "number of features: 216\n",
      "On test set:\n",
      "Residual sum of squares: 0.43\n",
      "Variance score is: 0.42\n",
      "Correlation between predicted ratings and actual ratings is: 0.6502\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.5666\n",
      " \n",
      "On training set:\n",
      "Residual sum of squares: 0.30\n",
      "Variance score is: 0.61\n",
      "Correlation between predicted ratings and actual ratings is: 0.7823\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.6954\n",
      "****************************************************************************************\n",
      "trustworthy\n",
      "mean rating:  5.60900627543\n",
      "235\n",
      "**************************Result of train and test**************************************\n",
      "number of features: 235\n",
      "On test set:\n",
      "Residual sum of squares: 0.42\n",
      "Variance score is: 0.51\n",
      "Correlation between predicted ratings and actual ratings is: 0.7158\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.6612\n",
      " \n",
      "On training set:\n",
      "Residual sum of squares: 0.31\n",
      "Variance score is: 0.65\n",
      "Correlation between predicted ratings and actual ratings is: 0.8081\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.7556\n",
      "****************************************************************************************\n",
      "unattractive\n",
      "mean rating:  4.26256222862\n",
      "193\n",
      "**************************Result of train and test**************************************\n",
      "number of features: 193\n",
      "On test set:\n",
      "Residual sum of squares: 0.68\n",
      "Variance score is: 0.46\n",
      "Correlation between predicted ratings and actual ratings is: 0.6801\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.6701\n",
      " \n",
      "On training set:\n",
      "Residual sum of squares: 0.49\n",
      "Variance score is: 0.63\n",
      "Correlation between predicted ratings and actual ratings is: 0.7946\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.7919\n",
      "****************************************************************************************\n",
      "unemotional\n",
      "mean rating:  3.81256567687\n",
      "164\n",
      "**************************Result of train and test**************************************\n",
      "number of features: 164\n",
      "On test set:\n",
      "Residual sum of squares: 0.48\n",
      "Variance score is: 0.51\n",
      "Correlation between predicted ratings and actual ratings is: 0.7146\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.6964\n",
      " \n",
      "On training set:\n",
      "Residual sum of squares: 0.33\n",
      "Variance score is: 0.65\n",
      "Correlation between predicted ratings and actual ratings is: 0.8096\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.7993\n",
      "****************************************************************************************\n",
      "unfamiliar\n",
      "mean rating:  4.4013349892\n",
      "89\n",
      "**************************Result of train and test**************************************\n",
      "number of features: 89\n",
      "On test set:\n",
      "Residual sum of squares: 0.37\n",
      "Variance score is: 0.17\n",
      "Correlation between predicted ratings and actual ratings is: 0.4241\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.3988\n",
      " \n",
      "On training set:\n",
      "Residual sum of squares: 0.35\n",
      "Variance score is: 0.29\n",
      "Correlation between predicted ratings and actual ratings is: 0.5399\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.5184\n",
      "****************************************************************************************\n",
      "unfriendly\n",
      "mean rating:  3.62069081908\n",
      "298\n",
      "**************************Result of train and test**************************************\n",
      "number of features: 298\n",
      "On test set:\n",
      "Residual sum of squares: 0.68\n",
      "Variance score is: 0.57\n",
      "Correlation between predicted ratings and actual ratings is: 0.7571\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.7117\n",
      " \n",
      "On training set:\n",
      "Residual sum of squares: 0.39\n",
      "Variance score is: 0.75\n",
      "Correlation between predicted ratings and actual ratings is: 0.8653\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.8212\n",
      "****************************************************************************************\n",
      "unhappy\n",
      "mean rating:  3.6158184685\n",
      "288\n",
      "**************************Result of train and test**************************************\n",
      "number of features: 288\n",
      "On test set:\n",
      "Residual sum of squares: 0.65\n",
      "Variance score is: 0.62\n",
      "Correlation between predicted ratings and actual ratings is: 0.7906\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.7416\n",
      " \n",
      "On training set:\n",
      "Residual sum of squares: 0.40\n",
      "Variance score is: 0.76\n",
      "Correlation between predicted ratings and actual ratings is: 0.8744\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.8279\n",
      "****************************************************************************************\n",
      "weird\n",
      "mean rating:  3.63755814401\n",
      "119\n",
      "**************************Result of train and test**************************************\n",
      "number of features: 119\n",
      "On test set:\n",
      "Residual sum of squares: 0.67\n",
      "Variance score is: 0.31\n",
      "Correlation between predicted ratings and actual ratings is: 0.5563\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.5271\n",
      " \n",
      "On training set:\n",
      "Residual sum of squares: 0.52\n",
      "Variance score is: 0.42\n",
      "Correlation between predicted ratings and actual ratings is: 0.6524\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.6295\n",
      "****************************************************************************************\n",
      "aggressive\n",
      "mean rating:  3.68906388164\n",
      "235\n",
      "**************************Result of train and test**************************************\n",
      "number of features: 235\n",
      "On test set:\n",
      "Residual sum of squares: 0.62\n",
      "Variance score is: 0.49\n",
      "Correlation between predicted ratings and actual ratings is: 0.7021\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.6404\n",
      " \n",
      "On training set:\n",
      "Residual sum of squares: 0.45\n",
      "Variance score is: 0.65\n",
      "Correlation between predicted ratings and actual ratings is: 0.8097\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.7531\n",
      "****************************************************************************************\n",
      "attractive\n",
      "mean rating:  4.938305509\n",
      "350\n",
      "**************************Result of train and test**************************************\n",
      "number of features: 350\n",
      "On test set:\n",
      "Residual sum of squares: 0.61\n",
      "Variance score is: 0.56\n",
      "Correlation between predicted ratings and actual ratings is: 0.7465\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.7464\n",
      " \n",
      "On training set:\n",
      "Residual sum of squares: 0.39\n",
      "Variance score is: 0.74\n",
      "Correlation between predicted ratings and actual ratings is: 0.8612\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.8570\n",
      "****************************************************************************************\n",
      "caring\n",
      "mean rating:  5.54319240594\n",
      "278\n",
      "**************************Result of train and test**************************************\n",
      "number of features: 278\n",
      "On test set:\n",
      "Residual sum of squares: 0.45\n",
      "Variance score is: 0.59\n",
      "Correlation between predicted ratings and actual ratings is: 0.7705\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.7183\n",
      " \n",
      "On training set:\n",
      "Residual sum of squares: 0.31\n",
      "Variance score is: 0.73\n",
      "Correlation between predicted ratings and actual ratings is: 0.8579\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.8279\n",
      "****************************************************************************************\n",
      "emotStable\n",
      "mean rating:  5.72547014446\n",
      "232\n",
      "**************************Result of train and test**************************************\n",
      "number of features: 232\n",
      "On test set:\n",
      "Residual sum of squares: 0.40\n",
      "Variance score is: 0.41\n",
      "Correlation between predicted ratings and actual ratings is: 0.6449\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.5728\n",
      " \n",
      "On training set:\n",
      "Residual sum of squares: 0.31\n",
      "Variance score is: 0.58\n",
      "Correlation between predicted ratings and actual ratings is: 0.7656\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.6866\n",
      "****************************************************************************************\n",
      "emotional\n",
      "mean rating:  4.85457467462\n",
      "92\n",
      "**************************Result of train and test**************************************\n",
      "number of features: 92\n",
      "On test set:\n",
      "Residual sum of squares: 0.31\n",
      "Variance score is: 0.34\n",
      "Correlation between predicted ratings and actual ratings is: 0.5890\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.6054\n",
      " \n",
      "On training set:\n",
      "Residual sum of squares: 0.28\n",
      "Variance score is: 0.46\n",
      "Correlation between predicted ratings and actual ratings is: 0.6790\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.6930\n",
      "****************************************************************************************\n",
      "familiar\n",
      "mean rating:  4.82254823987\n",
      "106\n",
      "**************************Result of train and test**************************************\n",
      "number of features: 106\n",
      "On test set:\n",
      "Residual sum of squares: 0.40\n",
      "Variance score is: 0.07\n",
      "Correlation between predicted ratings and actual ratings is: 0.3404\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.3036\n",
      " \n",
      "On training set:\n",
      "Residual sum of squares: 0.32\n",
      "Variance score is: 0.33\n",
      "Correlation between predicted ratings and actual ratings is: 0.5776\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.5428\n",
      "****************************************************************************************\n",
      "friendly\n",
      "mean rating:  5.82059405266\n",
      "324\n",
      "**************************Result of train and test**************************************\n",
      "number of features: 324\n",
      "On test set:\n",
      "Residual sum of squares: 0.57\n",
      "Variance score is: 0.62\n",
      "Correlation between predicted ratings and actual ratings is: 0.7911\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.7527\n",
      " \n",
      "On training set:\n",
      "Residual sum of squares: 0.33\n",
      "Variance score is: 0.79\n",
      "Correlation between predicted ratings and actual ratings is: 0.8884\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.8489\n",
      "****************************************************************************************\n",
      "happy\n",
      "mean rating:  5.76331922367\n",
      "283\n",
      "**************************Result of train and test**************************************\n",
      "number of features: 283\n",
      "On test set:\n",
      "Residual sum of squares: 0.60\n",
      "Variance score is: 0.69\n",
      "Correlation between predicted ratings and actual ratings is: 0.8301\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.8148\n",
      " \n",
      "On training set:\n",
      "Residual sum of squares: 0.38\n",
      "Variance score is: 0.80\n",
      "Correlation between predicted ratings and actual ratings is: 0.8969\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.8678\n",
      "****************************************************************************************\n",
      "humble\n",
      "mean rating:  5.25931088254\n",
      "206\n",
      "**************************Result of train and test**************************************\n",
      "number of features: 206\n",
      "On test set:\n",
      "Residual sum of squares: 0.47\n",
      "Variance score is: 0.34\n",
      "Correlation between predicted ratings and actual ratings is: 0.5964\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.5429\n",
      " \n",
      "On training set:\n",
      "Residual sum of squares: 0.36\n",
      "Variance score is: 0.53\n",
      "Correlation between predicted ratings and actual ratings is: 0.7306\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.6914\n",
      "****************************************************************************************\n",
      "interesting\n",
      "mean rating:  5.1925439811\n",
      "174\n",
      "**************************Result of train and test**************************************\n",
      "number of features: 174\n",
      "On test set:\n",
      "Residual sum of squares: 0.37\n",
      "Variance score is: 0.31\n",
      "Correlation between predicted ratings and actual ratings is: 0.5646\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.5602\n",
      " \n",
      "On training set:\n",
      "Residual sum of squares: 0.29\n",
      "Variance score is: 0.49\n",
      "Correlation between predicted ratings and actual ratings is: 0.7050\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.6846\n",
      "****************************************************************************************\n",
      "irresponsible\n",
      "mean rating:  3.49412266427\n",
      "195\n",
      "**************************Result of train and test**************************************\n",
      "number of features: 195\n",
      "On test set:\n",
      "Residual sum of squares: 0.42\n",
      "Variance score is: 0.38\n",
      "Correlation between predicted ratings and actual ratings is: 0.6278\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.5355\n",
      " \n",
      "On training set:\n",
      "Residual sum of squares: 0.34\n",
      "Variance score is: 0.60\n",
      "Correlation between predicted ratings and actual ratings is: 0.7768\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.6949\n",
      "****************************************************************************************\n",
      "mean\n",
      "mean rating:  3.50907456256\n",
      "267\n",
      "**************************Result of train and test**************************************\n",
      "number of features: 267\n",
      "On test set:\n",
      "Residual sum of squares: 0.61\n",
      "Variance score is: 0.52\n",
      "Correlation between predicted ratings and actual ratings is: 0.7226\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.6455\n",
      " \n",
      "On training set:\n",
      "Residual sum of squares: 0.43\n",
      "Variance score is: 0.69\n",
      "Correlation between predicted ratings and actual ratings is: 0.8300\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.7631\n",
      "****************************************************************************************\n",
      "memorable\n",
      "mean rating:  4.96662179163\n",
      "104\n",
      "**************************Result of train and test**************************************\n",
      "number of features: 104\n",
      "On test set:\n",
      "Residual sum of squares: 0.35\n",
      "Variance score is: 0.20\n",
      "Correlation between predicted ratings and actual ratings is: 0.4530\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.4322\n",
      " \n",
      "On training set:\n",
      "Residual sum of squares: 0.31\n",
      "Variance score is: 0.36\n",
      "Correlation between predicted ratings and actual ratings is: 0.6010\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.5831\n",
      "****************************************************************************************\n",
      "normal\n",
      "mean rating:  6.0043479721\n",
      "156\n",
      "**************************Result of train and test**************************************\n",
      "number of features: 156\n",
      "On test set:\n",
      "Residual sum of squares: 0.37\n",
      "Variance score is: 0.37\n",
      "Correlation between predicted ratings and actual ratings is: 0.6112\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.5601\n",
      " \n",
      "On training set:\n",
      "Residual sum of squares: 0.33\n",
      "Variance score is: 0.50\n",
      "Correlation between predicted ratings and actual ratings is: 0.7115\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.6484\n",
      "****************************************************************************************\n",
      "sociable\n",
      "mean rating:  5.81801230153\n",
      "243\n",
      "**************************Result of train and test**************************************\n",
      "number of features: 243\n",
      "On test set:\n",
      "Residual sum of squares: 0.50\n",
      "Variance score is: 0.59\n",
      "Correlation between predicted ratings and actual ratings is: 0.7703\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.7332\n",
      " \n",
      "On training set:\n",
      "Residual sum of squares: 0.35\n",
      "Variance score is: 0.73\n",
      "Correlation between predicted ratings and actual ratings is: 0.8539\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.8143\n",
      "****************************************************************************************\n",
      "typical\n",
      "mean rating:  5.28849724392\n",
      "127\n",
      "**************************Result of train and test**************************************\n",
      "number of features: 127\n",
      "On test set:\n",
      "Residual sum of squares: 0.35\n",
      "Variance score is: 0.15\n",
      "Correlation between predicted ratings and actual ratings is: 0.4130\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.3738\n",
      " \n",
      "On training set:\n",
      "Residual sum of squares: 0.30\n",
      "Variance score is: 0.32\n",
      "Correlation between predicted ratings and actual ratings is: 0.5640\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.5277\n",
      "****************************************************************************************\n",
      "uncertain\n",
      "mean rating:  3.71894901845\n",
      "137\n",
      "**************************Result of train and test**************************************\n",
      "number of features: 137\n",
      "On test set:\n",
      "Residual sum of squares: 0.42\n",
      "Variance score is: 0.40\n",
      "Correlation between predicted ratings and actual ratings is: 0.6326\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.6112\n",
      " \n",
      "On training set:\n",
      "Residual sum of squares: 0.34\n",
      "Variance score is: 0.49\n",
      "Correlation between predicted ratings and actual ratings is: 0.7037\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.6886\n",
      "****************************************************************************************\n",
      "uncommon\n",
      "mean rating:  3.8759900027\n",
      "92\n",
      "**************************Result of train and test**************************************\n",
      "number of features: 92\n",
      "On test set:\n",
      "Residual sum of squares: 0.35\n",
      "Variance score is: 0.19\n",
      "Correlation between predicted ratings and actual ratings is: 0.4391\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.3889\n",
      " \n",
      "On training set:\n",
      "Residual sum of squares: 0.33\n",
      "Variance score is: 0.26\n",
      "Correlation between predicted ratings and actual ratings is: 0.5066\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.4931\n",
      "****************************************************************************************\n",
      "unintelligent\n",
      "mean rating:  3.41764200135\n",
      "159\n",
      "**************************Result of train and test**************************************\n",
      "number of features: 159\n",
      "On test set:\n",
      "Residual sum of squares: 0.37\n",
      "Variance score is: 0.30\n",
      "Correlation between predicted ratings and actual ratings is: 0.5594\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.4931\n",
      " \n",
      "On training set:\n",
      "Residual sum of squares: 0.33\n",
      "Variance score is: 0.48\n",
      "Correlation between predicted ratings and actual ratings is: 0.6977\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.6121\n",
      "****************************************************************************************\n",
      "untrustworthy\n",
      "mean rating:  3.65333764671\n",
      "235\n",
      "**************************Result of train and test**************************************\n",
      "number of features: 235\n",
      "On test set:\n",
      "Residual sum of squares: 0.50\n",
      "Variance score is: 0.47\n",
      "Correlation between predicted ratings and actual ratings is: 0.6898\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.6091\n",
      " \n",
      "On training set:\n",
      "Residual sum of squares: 0.40\n",
      "Variance score is: 0.62\n",
      "Correlation between predicted ratings and actual ratings is: 0.7899\n",
      "Spearman Correlation between predicted ratings and actual ratings is: 0.7174\n",
      "****************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "modelList = []\n",
    "optFeaNumList = []\n",
    "import sys\n",
    "#print sys.path\n",
    "# local\n",
    "# PkgPath = '/Users/Olivialinlin/Documents/Github/attractiveness_datamining/linjieCode/code'\n",
    "# server\n",
    "PkgPath = homePath+'attractiveness_datamining/linjieCode/code'\n",
    "\n",
    "if PkgPath not in sys.path:\n",
    "    sys.path.insert(0, PkgPath)\n",
    "#print sys.path\n",
    "from xVal_train_test import Train_Test\n",
    "\n",
    "import sklearn\n",
    "import numpy as np\n",
    "for attr in social2Attr:\n",
    "    print attr\n",
    "    #attr= social2Attr[9]\n",
    "    mean_rating = socialMeasures.loc[:,attr].tolist()\n",
    "    mean_rating = map(float, mean_rating)\n",
    "    mean_rating = np.array(mean_rating)\n",
    "    radomRating = mean_rating[randomInd]\n",
    "    testRating = radomRating[:int(nSamples*testRatio)]\n",
    "    trainRating = radomRating[int(nSamples*testRatio):]\n",
    "    valiRating = radomRating[-int(trainRating.shape[0]*valiRatio):]\n",
    "    trainSubRating = trainRating[:-int(trainRating.shape[0]*valiRatio)]\n",
    "    #writeFile(trainIm,trainRating,'../list/'+attr+'_train.txt')\n",
    "    #writeFile(testIm,testRating,'../list/'+attr+'_test.txt')\n",
    "    writeFile(trainIm,trainRating,'../data_list/'+attr+'_train.txt')\n",
    "    writeFile(testIm,testRating,'../data_list/'+attr+'_test.txt')\n",
    "    baseLine = mean_rating.mean()\n",
    "    print 'mean rating: ', baseLine\n",
    "    ind = social2Attr.index(attr)\n",
    "    print hyP[ind]\n",
    "    predictionModel = sklearn.linear_model.RidgeCV(alphas=np.logspace(-3,2,num=20), fit_intercept=True)\n",
    "    myModel,optFeaNum = Train_Test(trainSubRating,testRating,valiRating,trainfeature_transf, \\\n",
    "                                   testfeature_tansf,valifeature_transf,xVal = False, hyperParam = hyP[ind],\\\n",
    "                                   numTrain = 1, pModel = predictionModel,getMaxMin = False,MODEL= MODEL, \\\n",
    "                                   plotPredActual = False,returnModel = True)\n",
    "    modelList.append(myModel)\n",
    "    optFeaNumList.append(optFeaNum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ind  = social2Attr.index('attractive')\n",
    "attr_model = modelList[ind]\n",
    "np.savetxt(homePath+'/features/'+MODEL+'_'+featureLayer+'_'+Dataset+\\\n",
    "           'other_coef.csv', attr_model.coef_, delimiter=',')\n",
    "np.savetxt(homePath+'/features/'+MODEL+'_'+featureLayer+'_'+Dataset+\\\n",
    "           'other_intercept.csv', np.asarray([attr_model.intercept_]), delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.savetxt(homePath+'/features/'+MODEL+'_'+featureLayer+'_'+Dataset+\\\n",
    "           'optNumF.csv', np.asarray(optFeaNumList), delimiter=',', fmt='%d')\n",
    "print optFeaNumList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atypical', 'boring', 'calm', 'cold', 'common', 'confident', 'egotistic', 'emotUnstable', 'forgettable', 'intelligent', 'introverted', 'kind', 'responsible', 'trustworthy', 'unattractive', 'unemotional', 'unfamiliar', 'unfriendly', 'unhappy', 'weird', 'aggressive', 'attractive', 'caring', 'emotStable', 'emotional', 'familiar', 'friendly', 'happy', 'humble', 'interesting', 'irresponsible', 'mean', 'memorable', 'normal', 'sociable', 'typical', 'uncertain', 'uncommon', 'unintelligent', 'untrustworthy']\n"
     ]
    }
   ],
   "source": [
    "predictRatingAll = np.zeros(socialMeasuresClean.shape)\n",
    "for i in range(len(modelList)):\n",
    "    m = modelList[i]\n",
    "    num = optFeaNumList[i]\n",
    "    featureOpt = feature_transf[:,:num]\n",
    "    #print featureOpt.shape\n",
    "    predictRatingAll[:,i] = m.predict(featureOpt)\n",
    "np.savetxt('/home/lli-ms/features/'+MODEL+'_'+featureLayer+'_'+Dataset+\\\n",
    "           '_predict_ratings.csv', predictRatingAll, delimiter=',')\n",
    "correlationAll = np.corrcoef(predictRatingAll.T)\n",
    "print social2Attr\n",
    "np.savetxt('predictCorrelation.csv', correlationAll, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from plotFunc import plotHeatMap\n",
    "import pandas as pd\n",
    "p = pd.read_csv('./correlation_array', index_col = 0)\n",
    "column_name = p.columns.tolist()\n",
    "data = p.as_matrix()\n",
    "print column_name == social2Attr\n",
    "# print column_name\n",
    "# plotHeatMap(data,clusterNum= 15,xTickLabel=column_name,\\\n",
    "#             colorMapName='coolwarm',figName = '',fSize = 3.5\\\n",
    "#             ,dendro = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "513.88521410103363"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "((data-data.mean())**2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.6422029834416172"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(data-data.mean(),(data-data.mean()).T).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.566725911542031"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
