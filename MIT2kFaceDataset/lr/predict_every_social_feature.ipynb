{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn import cross_validation\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(context=\"paper\", font=\"monospace\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "social_feature = pd.read_csv('reordered_social_feature.csv')\n",
    "geometric_feature = pd.read_csv('../clean_data/geometric_features.csv')\n",
    "geometric_feature.drop(['imgName'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "geofeature_fields = list(geometric_feature.columns.values)\n",
    "feature_x = geometric_feature.values\n",
    "feature_x = preprocessing.scale(feature_x)  # normalize the feature matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare parameters for ridge regression\n",
    "itr_num = 50\n",
    "random_seed = np.random.randint(1, 1000, size=itr_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atypical 0.335177673075\n",
      "boring 0.45921514156\n",
      "calm 0.322099541106\n",
      "cold 0.670713552459\n",
      "common 0.299396628375\n",
      "confident 0.449025945293\n",
      "egotistic 0.452982796961\n",
      "emotUnstable 0.470349188091\n",
      "forgettable 0.315014768085\n",
      "intelligent 0.387927631862\n",
      "introverted 0.568739949631\n",
      "kind 0.652866841569\n",
      "responsible 0.485362880866\n",
      "trustworthy 0.5637703231\n",
      "unattractive 0.485234003402\n",
      "unemotional 0.657738507487\n",
      "unfamiliar 0.331490135467\n",
      "unfriendly 0.662232382747\n",
      "unhappy 0.683555630917\n",
      "weird 0.408092660947\n",
      "aggressive 0.54102207294\n",
      "attractive 0.52518612857\n",
      "caring 0.629612937276\n",
      "emotStable 0.49520125549\n",
      "emotional 0.532345099183\n",
      "familiar 0.356516152192\n",
      "friendly 0.691214579202\n",
      "happy 0.735539932109\n",
      "humble 0.467060244959\n",
      "interesting 0.43336534892\n",
      "irresponsible 0.45070326992\n",
      "mean 0.585285090233\n",
      "memorable 0.303485153397\n",
      "normal 0.450686023093\n",
      "sociable 0.657483677902\n",
      "typical 0.342438938183\n",
      "uncertain 0.5287648791\n",
      "uncommon 0.304350613725\n",
      "unintelligent 0.383504409286\n",
      "untrustworthy 0.530074131769\n"
     ]
    }
   ],
   "source": [
    "for cur_ind in range(social_feature.shape[1]):\n",
    "    cur_feature = social_feature.ix[:,cur_ind]\n",
    "    cur_feature_name = cur_feature.name\n",
    "    y = cur_feature.values\n",
    "        \n",
    "    test_corr_list = np.zeros((itr_num, 1))\n",
    "    coef_list = np.zeros((feature_x.shape[1], itr_num))\n",
    "    intercept_list = np.zeros((itr_num, 1))\n",
    "    alpha_list = np.zeros((itr_num, 1))\n",
    "    alphas = np.logspace(-3, 2, num=20)\n",
    "\n",
    "    for cur_itr in range(itr_num):\n",
    "        x_train, x_test, y_train, y_test = cross_validation.train_test_split(feature_x, y, test_size=0.5, random_state=random_seed[cur_itr])\n",
    "        clf = linear_model.RidgeCV(alphas=alphas, fit_intercept=True)\n",
    "        clf.fit(x_train, y_train)\n",
    "\n",
    "        coef_list[:, cur_itr] = clf.coef_\n",
    "        intercept_list[cur_itr] = clf.intercept_\n",
    "        alpha_list[cur_itr] = clf.alpha_\n",
    "\n",
    "        y_test_pred = clf.predict(x_test)\n",
    "        corr = spearmanr(y_test, y_test_pred)\n",
    "        test_corr_list[cur_itr] = corr[0]\n",
    "\n",
    "    print cur_feature_name, test_corr_list.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use all the other features to predict attractiveness\n",
    "full_attribute = pd.concat([geometric_feature, social_feature])\n",
    "\n",
    "attract_y = full_attribute['attractive']\n",
    "full_attribute.drop(['attractive'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-79-f6f0316fda14>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mall_feature_fields\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_attribute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mfeature_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfull_attribute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mfeature_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_attribute\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# normalize the feature matrix.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.pyc\u001b[0m in \u001b[0;36mscale\u001b[1;34m(X, axis, with_mean, with_std, copy)\u001b[0m\n\u001b[0;32m    127\u001b[0m     X = check_array(X, accept_sparse='csr', copy=copy, ensure_2d=False,\n\u001b[0;32m    128\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'the scale function'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 129\u001b[1;33m                     dtype=FLOAT_DTYPES)\n\u001b[0m\u001b[0;32m    130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mwith_mean\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    396\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[0;32m    397\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 398\u001b[1;33m             \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    399\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    400\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m     52\u001b[0m             and not np.isfinite(X).all()):\n\u001b[0;32m     53\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[1;32m---> 54\u001b[1;33m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "all_feature_fields = list(full_attribute.columns.values)\n",
    "feature_x = full_attribute.values\n",
    "feature_x = preprocessing.scale(full_attribute)  # normalize the feature matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4414, 71)"
      ]
     },
     "execution_count": 78,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "full_attribute.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}